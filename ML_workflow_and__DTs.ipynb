{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d6adbc7b",
      "metadata": {
        "id": "d6adbc7b"
      },
      "source": [
        "# ML workflow and decision trees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af3e65b6",
      "metadata": {
        "id": "af3e65b6"
      },
      "source": [
        "by: Amr Mohamed and Anh Thu Doan "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "159b640f",
      "metadata": {
        "id": "159b640f"
      },
      "source": [
        "# Data exploration and preparation to be used for training and predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "df9fd728",
      "metadata": {
        "id": "df9fd728"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt   \n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "from collections import Counter\n",
        "from graphviz import Digraph\n",
        "import matplotlib.pyplot as plt   \n",
        "from numpy import arange\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "from sklearn.dummy import DummyClassifier,DummyRegressor\n",
        "from sklearn.metrics import accuracy_score,mean_squared_error,mean_squared_error\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,GradientBoostingRegressor,RandomForestRegressor\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, GridSearchCV,train_test_split,cross_validate,RepeatedKFold\n",
        "from sklearn.linear_model import LogisticRegression,Perceptron,LinearRegression,Lasso, Ridge\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor,MLPClassifier\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao8QQ2e9pVyj",
        "outputId": "fce626f6-3d84-4739-a8ec-d6f8c5afe71b"
      },
      "id": "ao8QQ2e9pVyj",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98e9d8d",
      "metadata": {
        "id": "a98e9d8d"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file.\n",
        "data = pd.read_csv('//content//drive//MyDrive//Data//CTG.csv', skiprows=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a3b3abc",
      "metadata": {
        "id": "0a3b3abc"
      },
      "outputs": [],
      "source": [
        "# Select the relevant numerical columns.\n",
        "selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',\n",
        "                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',\n",
        "                 'Median', 'Variance', 'Tendency', 'NSP']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10eace4d",
      "metadata": {
        "id": "10eace4d"
      },
      "outputs": [],
      "source": [
        "data = data[selected_cols].dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b66f552",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "3b66f552",
        "outputId": "fd0b40c6-85fd-4262-db0c-8d9ce2ce5ccb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      LB   AC   FM   UC   DL   DS   DP  ASTV  MSTV  ALTV  ...   Min    Max  \\\n",
              "0  120.0  0.0  0.0  0.0  0.0  0.0  0.0  73.0   0.5  43.0  ...  62.0  126.0   \n",
              "1  132.0  4.0  0.0  4.0  2.0  0.0  0.0  17.0   2.1   0.0  ...  68.0  198.0   \n",
              "2  133.0  2.0  0.0  5.0  2.0  0.0  0.0  16.0   2.1   0.0  ...  68.0  198.0   \n",
              "3  134.0  2.0  0.0  6.0  2.0  0.0  0.0  16.0   2.4   0.0  ...  53.0  170.0   \n",
              "4  132.0  4.0  0.0  5.0  0.0  0.0  0.0  16.0   2.4   0.0  ...  53.0  170.0   \n",
              "\n",
              "   Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  NSP  \n",
              "0   2.0     0.0  120.0  137.0   121.0      73.0       1.0  2.0  \n",
              "1   6.0     1.0  141.0  136.0   140.0      12.0       0.0  1.0  \n",
              "2   5.0     1.0  141.0  135.0   138.0      13.0       0.0  1.0  \n",
              "3  11.0     0.0  137.0  134.0   137.0      13.0       1.0  1.0  \n",
              "4   9.0     0.0  137.0  136.0   138.0      11.0       1.0  1.0  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17568957-6fc9-49d7-8e2f-a979d213b5b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LB</th>\n",
              "      <th>AC</th>\n",
              "      <th>FM</th>\n",
              "      <th>UC</th>\n",
              "      <th>DL</th>\n",
              "      <th>DS</th>\n",
              "      <th>DP</th>\n",
              "      <th>ASTV</th>\n",
              "      <th>MSTV</th>\n",
              "      <th>ALTV</th>\n",
              "      <th>...</th>\n",
              "      <th>Min</th>\n",
              "      <th>Max</th>\n",
              "      <th>Nmax</th>\n",
              "      <th>Nzeros</th>\n",
              "      <th>Mode</th>\n",
              "      <th>Mean</th>\n",
              "      <th>Median</th>\n",
              "      <th>Variance</th>\n",
              "      <th>Tendency</th>\n",
              "      <th>NSP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>62.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>132.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>68.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>68.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>134.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>53.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>132.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>53.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17568957-6fc9-49d7-8e2f-a979d213b5b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17568957-6fc9-49d7-8e2f-a979d213b5b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17568957-6fc9-49d7-8e2f-a979d213b5b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0648208c",
      "metadata": {
        "id": "0648208c"
      },
      "outputs": [],
      "source": [
        "# Shuffle the dataset.\n",
        "data_shuffled = data.sample(frac=1.0, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28cb83be",
      "metadata": {
        "id": "28cb83be"
      },
      "outputs": [],
      "source": [
        "# Split into input part X and output part Y.\n",
        "X = data_shuffled.drop('NSP', axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6370b955",
      "metadata": {
        "id": "6370b955"
      },
      "outputs": [],
      "source": [
        "# Map the diagnosis code to a human-readable label.\n",
        "def to_label(y):\n",
        "    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc63a48b",
      "metadata": {
        "id": "dc63a48b"
      },
      "outputs": [],
      "source": [
        "Y = data_shuffled['NSP'].apply(to_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2444ab8",
      "metadata": {
        "id": "c2444ab8"
      },
      "outputs": [],
      "source": [
        "# Partition the data into training and test sets.\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b41fd7b7",
      "metadata": {
        "id": "b41fd7b7"
      },
      "source": [
        "# Baseline classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de53d27d",
      "metadata": {
        "id": "de53d27d"
      },
      "source": [
        "# Dummy Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b967cf39",
      "metadata": {
        "id": "b967cf39"
      },
      "outputs": [],
      "source": [
        "dummy = DummyClassifier(strategy='most_frequent')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d403923",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d403923",
        "outputId": "9362d871-f0b5-448f-a4af-ba112a6bd46a",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7805882352941176"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "cross_val_score(dummy, Xtrain, Ytrain).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a625604",
      "metadata": {
        "id": "8a625604"
      },
      "source": [
        "By cross-validating the dummy classifier on the training data's different fold, we get a mean accuracy of <b>78% </b> in predicting the classification of the fetal states into the three class Normal, Suspicious, or Pathological."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e362216b",
      "metadata": {
        "id": "e362216b"
      },
      "source": [
        "## Training and hyperparameter-tuning a set of different ML classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5fbe024",
      "metadata": {
        "id": "a5fbe024"
      },
      "source": [
        "In this section we are going to expirement few different types of classifiers for the aim of finding the classifier with the highest accuracy in the differentiation task of the fetal states classification."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97d62b88",
      "metadata": {
        "id": "97d62b88"
      },
      "source": [
        "# Tree-based classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5725955f",
      "metadata": {
        "id": "5725955f"
      },
      "source": [
        "We firstly start by experimenting the Decision Tree classifier of sklearn on our training data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea90f924",
      "metadata": {
        "id": "ea90f924"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4496f23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4496f23",
        "outputId": "07bff963-a590-4dc4-8228-76a0f6c4057e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9199999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "skDT = DecisionTreeClassifier()\n",
        "cross_val_score(skDT, Xtrain, Ytrain).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "388cf2ed",
      "metadata": {
        "id": "388cf2ed"
      },
      "source": [
        "As we can see, the DT classifier obtained a cross-validation accuracy of an average of <b>92.4%</b> on the different folds of the training data when being called with the default values of its parameters, so we proceed by tuning the classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0030b8e2",
      "metadata": {
        "id": "0030b8e2"
      },
      "source": [
        "### DecisionTree hyperparameter (max_depth) tuning through a graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9e99331",
      "metadata": {
        "id": "d9e99331"
      },
      "source": [
        "plot to verify the determine the max_depth hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92cd58c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "92cd58c8",
        "outputId": "db353d48-9d81-404d-ee36-d55a14a7c5da",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "max_depths = np.linspace(1, 50, 50, endpoint=True)\n",
        "\n",
        "train_results = []\n",
        "\n",
        "for max_depth in max_depths:\n",
        "    dt = DecisionTreeClassifier(max_depth=max_depth,random_state=0)\n",
        "    accuracyTemp = cross_val_score(dt, Xtrain, Ytrain).mean()\n",
        "    train_results.append(accuracyTemp)\n",
        "    \n",
        "line2 = plt.plot(max_depths, train_results, label='Train accuracy')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Tree depth')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5706ef3",
      "metadata": {
        "id": "a5706ef3"
      },
      "source": [
        "As we can see in the graph, the maximum depth maximizes the accuracy of the DT classifier when its maximimum depth is between 8-10 approximately and decreases to stay constant after the depth of 18. (This cv accuracy values are guaranteed when the max_depth is varying while the other parameters are held with their default values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46208e1e",
      "metadata": {
        "id": "46208e1e"
      },
      "source": [
        "### DecisionTree hyperparameter tuning using sklearn gridsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fa2feaa",
      "metadata": {
        "id": "8fa2feaa"
      },
      "source": [
        "Moving on, to tune the hyperparameters max_depth and criterion with different combinations of their values in order to find the best combination that maximizes the model's csv average accuracy, we use sklearn's gridsearch meathod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcea0ab7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcea0ab7",
        "outputId": "596c3f0e-32a0-49c1-93d9-3bf3a905af27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=0), n_jobs=-1,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [3, 5, 6, 7, 8, 9, 10, 40, 70, 100]})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "dTgridTuned = DecisionTreeClassifier(random_state=0)\n",
        "parameter_space = {'max_depth': [3,5,6,7,8,9,10,40,70,100],\n",
        "                'criterion': ['gini','entropy']}\n",
        "DtTuned = GridSearchCV(dTgridTuned, parameter_space, n_jobs=-1, cv=5)\n",
        "DtTuned.fit(Xtrain, Ytrain) # X is train samples and y is the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4af814dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4af814dc",
        "outputId": "299ce3d8-8f00-4edb-d34e-670952980c4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy', 'max_depth': 40}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "DtTuned.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "496487d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "496487d3",
        "outputId": "e7fb650b-af51-464f-963b-b255fe9c2013",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9341176470588234"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "DtTuned.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8b26160",
      "metadata": {
        "id": "b8b26160"
      },
      "source": [
        "By running searching the search space of the different combination of both parameters, the gridsearch found that when <b> criterion = 'entropy'</b> and <b> max_depth = 40</b>, the cv accuracy is maximized to <b>93.4% </b> in predicting the status of the fetus."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0462e16",
      "metadata": {
        "id": "b0462e16"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffd5b0d0",
      "metadata": {
        "id": "ffd5b0d0"
      },
      "source": [
        "Afterwards, we moved forward to experiment the Random Forest classifier model, since the Decision tree classifier performed well compared to the baseline dummy classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dba30d2c",
      "metadata": {
        "id": "dba30d2c",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb84de0d-4078-4c9a-e041-5cbdbd4c1740"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9429411764705883"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "RF = RandomForestClassifier(random_state=0)\n",
        "cross_val_score(RF, Xtrain, Ytrain).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61e2d5ae",
      "metadata": {
        "id": "61e2d5ae"
      },
      "source": [
        "As we can see, the RF classifier obtained a cross-validation accuracy of an average of <b>94%</b> on the different folds of the training data when being called with the default values of its parameters, so we proceed by tuning the classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0225017",
      "metadata": {
        "id": "d0225017"
      },
      "source": [
        "### n_estimators hyperparameter tuning with graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f458409",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "5f458409",
        "outputId": "f0f34084-11f6-4a71-b74d-38bf0bf91b97",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200,500]\n",
        "train_results = []\n",
        "for estimator in n_estimators:\n",
        "    RF = RandomForestClassifier(n_estimators=estimator,random_state=0)\n",
        "    accuracyTemp = cross_val_score(RF, Xtrain, Ytrain).mean()\n",
        "    train_results.append(accuracyTemp)\n",
        "    \n",
        "plt.plot(n_estimators, train_results, label='Train accuracy')\n",
        "\n",
        "plt.ylabel('Accuracy score')\n",
        "plt.xlabel('Number of estimators')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2447e42d",
      "metadata": {
        "id": "2447e42d"
      },
      "source": [
        "As we can see in the graph above, the number of estimator trees that maximizes the accuracy of the RF classifier when its n_estimators is 120 estimators approximately and the accuracy starts in decreasing slightly as the number of estimators increases. (This cv accuracy values are guaranteed when the n_estimators is varying while the other parameters are held with their default values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fce57757",
      "metadata": {
        "id": "fce57757"
      },
      "source": [
        "### Random Forest Classifier hyperparameter tuning with gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c852475",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c852475",
        "outputId": "d7198b3a-7f0b-4a02-f649-286e1b8956ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [0, 2, 3, 5, 10, 40, 70, 100],\n",
              "                         'n_estimators': [1, 2, 4, 8, 16, 32, 64, 100, 200,\n",
              "                                          500]})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "RfCgridTuned = RandomForestClassifier()\n",
        "parameter_space = {'max_depth': [0,2,3,5,10,40,70,100],\n",
        "                 'criterion': ['gini', 'entropy'],\n",
        "                   'n_estimators' : [1, 2, 4, 8, 16, 32, 64, 100, 200,500]}\n",
        "RFCTuned = GridSearchCV(RfCgridTuned, parameter_space, n_jobs=-1, cv=5)\n",
        "RFCTuned.fit(Xtrain, Ytrain) # X is train samples and y is the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1fbbbdb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1fbbbdb",
        "outputId": "6cbd9b0e-ece9-4a85-dd54-796a21edb7e4",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini', 'max_depth': 70, 'n_estimators': 200}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "RFCTuned.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2105a151",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2105a151",
        "outputId": "9c62e683-c317-4d35-a2f8-3b4090ea78af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.943529411764706"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "RFCTuned.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee968be",
      "metadata": {
        "id": "8ee968be"
      },
      "source": [
        "As we can see, for the purpose of reaching a higher accuracy in the cross-validation phase, we tune the hyperparameter <i>maxdepth, criterion, and n_estimators </i> of the model using a gridsearch to find the the parameters that maximized the model's cv accuracy are <b>criterion = 'entropy', max_depth = 10, and n_estimators = 32</b> as by applying those parameters values on the model, the model acieved a cv accuracy of <b>94.4%</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db41d00e",
      "metadata": {
        "id": "db41d00e"
      },
      "source": [
        "## Gradient Boosting Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8217748d",
      "metadata": {
        "id": "8217748d"
      },
      "source": [
        "We continue to repeat the steps carried out on the models above for more models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0c67c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0c67c35",
        "outputId": "daaad787-61c1-4322-ec3e-186d9187fe21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9494117647058824"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "GBC = GradientBoostingClassifier(random_state=0)\n",
        "cross_val_score(GBC, Xtrain, Ytrain).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7beebb52",
      "metadata": {
        "id": "7beebb52"
      },
      "source": [
        "We experiment the Gradient Boosting Classifier model on the training data, and we find that with the model's default parameters, the model achived an average cross validation accuracy on the different folds of the training set of approximately <b> 95% </b>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97fe6cbc",
      "metadata": {
        "id": "97fe6cbc"
      },
      "source": [
        "### max_depth hyperparameter tuning through a graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f7f3ed9",
      "metadata": {
        "id": "0f7f3ed9"
      },
      "source": [
        "plot to verify the determine the max_depth hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f63aef8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "f63aef8d",
        "outputId": "ed9cb9ca-6fc1-44ae-a7a5-92c617944aef",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "max_depths = np.linspace(1, 10, 10, endpoint=True)\n",
        "\n",
        "train_results = []\n",
        "\n",
        "for max_depth in max_depths:\n",
        "    GBC = GradientBoostingClassifier(max_depth=max_depth,random_state=0)\n",
        "    accuracyTemp = cross_val_score(GBC, Xtrain, Ytrain).mean()\n",
        "    train_results.append(accuracyTemp)\n",
        "    \n",
        "plt.plot(max_depths, train_results, label='Train accuracy')\n",
        "    \n",
        "# plt.ylim(bottom=0)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Tree depth')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "266d1b24",
      "metadata": {
        "id": "266d1b24"
      },
      "source": [
        "By tuning the model's hyperparameter <b> max_depth</b>, we can see from the graph aove that the value of <b> max_depth</b> that maximizes the models average cross validation accuracy on the different fold of the training set is <b> max_depth = 6</b> that results in an avergae cv accuracy of aprroximately <b>95.2%</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a90d9312",
      "metadata": {
        "id": "a90d9312"
      },
      "source": [
        "### GradientBoosting Classifier hyperparameter tuning with gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8332799e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8332799e",
        "outputId": "9ac704f8-1279-4c8c-b834-3863fa7dea8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
              "             param_grid={'criterion': ['friedman_mse', 'squared_error', 'mse',\n",
              "                                       'mae'],\n",
              "                         'learning_rate': [0.001, 0.01, 1],\n",
              "                         'loss': ['deviance', 'exponential'],\n",
              "                         'n_estimators': [4, 8, 16, 64, 100]})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "GBCgridTuned = GradientBoostingClassifier()\n",
        "parameter_space = {'loss' : ['deviance', 'exponential'],\n",
        "                'criterion': ['friedman_mse', 'squared_error', 'mse', 'mae'],\n",
        "                'n_estimators' : [4, 8, 16, 64, 100]\n",
        "                ,'learning_rate': [0.001,0.01,1]\n",
        "                  }\n",
        "GBCTuned = GridSearchCV(GBCgridTuned, parameter_space, n_jobs=-1, cv=5)\n",
        "GBCTuned.fit(Xtrain, Ytrain) # X is train samples and y is the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e50cd73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e50cd73",
        "outputId": "c0121735-393d-44e2-e1b9-ad9e8447fa26",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'friedman_mse',\n",
              " 'learning_rate': 1,\n",
              " 'loss': 'deviance',\n",
              " 'n_estimators': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "GBCTuned.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c4fc2ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c4fc2ba",
        "outputId": "c47bec80-c94c-4db3-ae5b-bb1055add0d8",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9441176470588235"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "GBCTuned.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aa8acd6",
      "metadata": {
        "id": "3aa8acd6"
      },
      "source": [
        "furthermore, we tuned the differen hyperparameters of the model <b> loss, criterion, n_estimators, and learning_rate </b> using a gridsearch to get a best score of the different combination of the gridsearch of <b> 94.2%</b>, which is less than the average cross validation accuracy obtained by max_depth=6 with the rest of the parameters set to their defaults, therefore for the GradientBoosting Classifier model we use the graphically tuned version with <b>max_depth = 6</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mHwVqP2gafAY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHwVqP2gafAY",
        "outputId": "8c23bd56-4115-4597-a916-746219acb4f5",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9476470588235294"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "GBCFinal = GradientBoostingClassifier(max_depth = 6)\n",
        "cross_val_score(GBCFinal, Xtrain, Ytrain).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "167eda91",
      "metadata": {
        "id": "167eda91"
      },
      "source": [
        "# Linear Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "561a4ce6",
      "metadata": {
        "id": "561a4ce6"
      },
      "source": [
        "Afterwards, we moved forward to try a set of different linear classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645c3072",
      "metadata": {
        "id": "645c3072"
      },
      "source": [
        "## Perceptron Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "537ef959",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "537ef959",
        "outputId": "46775436-3d13-4326-9563-d36df3e2d8eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.825294117647059"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "perceptron = Perceptron()\n",
        "cross_val_score(perceptron, Xtrain, Ytrain).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c065050f",
      "metadata": {
        "id": "c065050f"
      },
      "source": [
        "For perceptron linear model, we obtaind an average cross validation accuracy on the different folds of the training set of <b>82.5%</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8a07bce",
      "metadata": {
        "id": "c8a07bce"
      },
      "source": [
        "### Hyperparameter tuning with sklearn grid search"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da06bb6a",
      "metadata": {
        "id": "da06bb6a"
      },
      "source": [
        "we tune the perceptron model based on the learning rate (alpha), penalty, and number of epochs as they are the most parameters having effect on the model's accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc08700",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdc08700",
        "outputId": "4274b610-814e-403d-a7ac-55e19201a1df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=Perceptron(), n_jobs=-1,\n",
              "             param_grid={'alpha': [1e-05, 0.0001, 0.0003, 0.001, 0.003, 0.01,\n",
              "                                   0.03, 0.1, 0.3],\n",
              "                         'max_iter': [3, 5, 10, 15, 20, 50],\n",
              "                         'penalty': ['l2', 'l1', 'elasticnet']})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "perceptron = Perceptron(random_state=0)\n",
        "parameter_space = {'alpha': [0.00001,0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3],\n",
        "                   'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "                'max_iter': [3,5, 10, 15, 20, 50]}\n",
        "perceptronTuned = GridSearchCV(perceptron, parameter_space, n_jobs=-1, cv=5)\n",
        "perceptronTuned.fit(Xtrain, Ytrain) # X is train samples and y is the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99f65b1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99f65b1e",
        "outputId": "2568287d-5bdf-4b29-f3b3-75f334a6300d",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.001, 'max_iter': 50, 'penalty': 'l1'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "perceptronTuned.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61b2714a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61b2714a",
        "outputId": "10533397-eb7b-4f9b-91a8-f7ac8aa02a07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8505882352941176"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "perceptronTuned.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e06cb600",
      "metadata": {
        "id": "e06cb600"
      },
      "source": [
        "By tuning the hyperparameters of the perceptron model using a grid search, the average cv accuracy on the different fold of the training set is raised to <b>85%</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5064cda",
      "metadata": {
        "id": "a5064cda"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be87666",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9be87666",
        "outputId": "d7192f44-b705-4929-ceea-5aa223cf3eaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8735294117647058"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "LogR = LogisticRegression()\n",
        "cross_val_score(LogR, Xtrain, Ytrain).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc5294b",
      "metadata": {
        "id": "9cc5294b"
      },
      "source": [
        "For the Logistic Regression model, we obtaind an average cross validation accuracy on the different folds of the training set of <b>87.4%</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8223ded",
      "metadata": {
        "id": "b8223ded"
      },
      "source": [
        "### Tuning logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcb7390d",
      "metadata": {
        "id": "bcb7390d"
      },
      "outputs": [],
      "source": [
        "LogRgridTuned = LogisticRegression()\n",
        "\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100,1000], 'penalty': ['l1', 'l2']}\n",
        "\n",
        "LogRTuned = GridSearchCV(LogRgridTuned, param_grid)\n",
        "\n",
        "LogRTuned.fit(Xtrain, Ytrain);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945710ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945710ff",
        "outputId": "a7fe161e-98aa-43e4-d114-f9dfae4c14a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.01, 'penalty': 'l2'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "LogRTuned.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "187caec5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "187caec5",
        "outputId": "3a5c4571-24eb-410a-d67a-91b342820fcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8823529411764707"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "LogRTuned.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe14dcfc",
      "metadata": {
        "id": "fe14dcfc"
      },
      "source": [
        "By tuning the logistic regression model on the <b> Inverse of regularization strength (C) and the norm of the penalty </b>, we find that the hyperparameter combination that maximizes the average cv accuracy to approximately <b> 88%</b> is <b> C = 0.01 and penalty = L2</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aaf77a7",
      "metadata": {
        "id": "0aaf77a7"
      },
      "source": [
        "## Linear Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63bbb589",
      "metadata": {
        "id": "63bbb589"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56358b42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56358b42",
        "outputId": "98c8ac60-e358-4a0d-b972-eb0bac1b33d4",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8452941176470589"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "lsvc = LinearSVC(random_state=0)\n",
        "cross_val_score(lsvc, Xtrain, Ytrain).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e9d7c1f",
      "metadata": {
        "id": "1e9d7c1f"
      },
      "source": [
        "For the Linear Support Vector Classifier model, we obtaind an average cross validation accuracy on the different folds of the training set of <b> 84.5%</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985a6c0f",
      "metadata": {
        "id": "985a6c0f"
      },
      "source": [
        "### Linear SVC hyperparameter tuning with gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d74eb7",
      "metadata": {
        "id": "f7d74eb7"
      },
      "outputs": [],
      "source": [
        "lsvcGridTuned = LinearSVC()\n",
        "\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100,1000], 'penalty': ['l1', 'l2'],'loss':['hinge', 'squared_hinge']}\n",
        "\n",
        "lsvcTuned = GridSearchCV(lsvcGridTuned, param_grid)\n",
        "\n",
        "lsvcTuned.fit(Xtrain, Ytrain);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0909f035",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0909f035",
        "outputId": "68492159-8b7e-47df-92df-bc3cfe4c248b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.01, 'loss': 'hinge', 'penalty': 'l2'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "lsvcTuned.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f457495f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f457495f",
        "outputId": "94ce151d-e29c-4950-aa68-3834275ded31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8735294117647058"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "lsvcTuned.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7924b252",
      "metadata": {
        "id": "7924b252"
      },
      "source": [
        "By tuning the Linear SVC model on the <b> the Regularization parameter (C), the loss function, and the norm of the penalty </b>, we find that the hyperparameter combination that maximizes the average cv accuracy to approximately <b> 88%</b> is <b> C = 100, loss = hinge,  and penalty = L2</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "749ee385",
      "metadata": {
        "id": "749ee385"
      },
      "source": [
        "# Neural network classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29fc2af1",
      "metadata": {
        "id": "29fc2af1"
      },
      "source": [
        "Moreover, we experiment the neural network based model Multilayer perceptron from sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IOnFRpdMwGRS",
      "metadata": {
        "id": "IOnFRpdMwGRS"
      },
      "source": [
        "## MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db704822",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db704822",
        "outputId": "eb208cb9-285e-4db6-c18f-1f63b124b88c",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8847058823529412"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "NNC = MLPClassifier(random_state=0)\n",
        "cross_val_score(NNC, Xtrain, Ytrain).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53de310d",
      "metadata": {
        "id": "53de310d"
      },
      "source": [
        "For the MLP Classifier model, we obtaind an average cross validation accuracy on the different folds of the training set of <b>88.5%</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9214b546",
      "metadata": {
        "id": "9214b546"
      },
      "source": [
        "### Hyperparameter tuning for NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GZVFwpKozAc3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZVFwpKozAc3",
        "outputId": "f8243a4e-6814-483d-dc9e-47319679e5dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=MLPClassifier(max_iter=100), n_jobs=-1,\n",
              "             param_grid={'activation': ['tanh', 'relu', 'logistic'],\n",
              "                         'alpha': [0.0001],\n",
              "                         'hidden_layer_sizes': [(1000,), (5000,)],\n",
              "                         'learning_rate': ['invscaling', 'adaptive'],\n",
              "                         'solver': ['adam']})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "mlp_gs = MLPClassifier(max_iter=100)\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(1000,),(5000,)],\n",
        "    'activation': ['tanh', 'relu','logistic'],\n",
        "    'solver': ['adam'],\n",
        "    'alpha': [0.0001],\n",
        "    'learning_rate': ['invscaling', 'adaptive'],\n",
        "}\n",
        "clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=5)\n",
        "clf.fit(Xtrain, Ytrain) # X is train samples and y is the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2rkNpdz0zLo6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rkNpdz0zLo6",
        "outputId": "15416f43-4f5f-41e2-b6ca-b2ac7b9048d8",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'tanh',\n",
              " 'alpha': 0.0001,\n",
              " 'hidden_layer_sizes': (1000,),\n",
              " 'learning_rate': 'adaptive',\n",
              " 'solver': 'adam'}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "clf.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ba75470",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ba75470",
        "outputId": "55e8a66f-b093-41ad-93b1-0e59ecf4e355"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.911764705882353"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "clf.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c4ead14",
      "metadata": {
        "id": "6c4ead14"
      },
      "source": [
        "By tuning the MLP classifier model on the parameter <b> number of hidden layers, activation function, solver, learning rate, and type of learning rate </b>, we obtained that the values of the parameters specified above resulted in an increase in the average cv accuracy to approximately <b> 91.2%</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "365ed689",
      "metadata": {
        "id": "365ed689"
      },
      "source": [
        "# Final evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a446fb8",
      "metadata": {
        "id": "4a446fb8"
      },
      "source": [
        "Moving forward, we choose the highest models scoring average cross validation accuracies to predict with them the testing set and evaluate their prediction accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a48e8ae9",
      "metadata": {
        "id": "a48e8ae9"
      },
      "source": [
        "### Cross Validation Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51816b47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51816b47",
        "outputId": "c74ef325-311b-4e70-8a02-7ecbdb043fe4",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cross-validation accuarcy of the Dummy Classifier is :0.781\n",
            "The cross-validation accuarcy of the Decision Tree Classifier is :0.934\n",
            "The cross-validation accuarcy of the Random Forest Classifier is :0.944\n",
            "The cross-validation accuarcy of the Gradient Boosting Classifier is :0.95\n",
            "The cross-validation accuarcy of the Perceptron Classifier is :0.851\n",
            "The cross-validation accuarcy of the Logistic Regression Classifier is :0.851\n",
            "The cross-validation accuarcy of the Linear support vector classifier is :0.874\n",
            "The cross-validation accuarcy of the Multi layer perceptron (MLP) Neural Network Classifier is :0.912\n"
          ]
        }
      ],
      "source": [
        "# Dummy Classifier\n",
        "print(\"The cross-validation accuarcy of the Dummy Classifier is :\"+str(round(cross_val_score(dummy, Xtrain, Ytrain).mean(),3)))\n",
        "# Decision Tree\n",
        "print(\"The cross-validation accuarcy of the Decision Tree Classifier is :\"+str(round(DtTuned.best_score_,3)))\n",
        "# Random Forset\n",
        "print(\"The cross-validation accuarcy of the Random Forest Classifier is :\"+str(round(RFCTuned.best_score_,3)))\n",
        "#Gradient Boosting\n",
        "print(\"The cross-validation accuarcy of the Gradient Boosting Classifier is :\"+str(round(cross_val_score(GBCFinal, Xtrain, Ytrain).mean(),3)))\n",
        "#Perceptron\n",
        "print(\"The cross-validation accuarcy of the Perceptron Classifier is :\"+str(round(perceptronTuned.best_score_,3)))\n",
        "# Logistic Regression\n",
        "print(\"The cross-validation accuarcy of the Logistic Regression Classifier is :\"+str(round(perceptronTuned.best_score_,3)))\n",
        "# LinearSVC\n",
        "print(\"The cross-validation accuarcy of the Linear support vector classifier is :\"+str(round(lsvcTuned.best_score_,3)))\n",
        "# Multi layer perceptron (MLP) Neural Network Classifier\n",
        "print(\"The cross-validation accuarcy of the Multi layer perceptron (MLP) Neural Network Classifier is :\"+str(round(clf.best_score_,3)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5d16a4f",
      "metadata": {
        "id": "e5d16a4f"
      },
      "source": [
        "We can see that the Gradient Boosting Classifier performed the best within the used classifiers in classification of the <b>  fetal states </b> into the three class <i>Normal<i>, <i>Suspicious<i>, or <i>Pathological<i> with a average validation accuracy of <b>95%</b> with a difference of 0.4% average cross-validation accuracy than the validation accuracy of the Random Forest Tree classifier, and 1.5% difference than the Decision Tree classifier, we proceed forward to test the prediction accuracy of those 3 models on the testing set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6085fa38",
      "metadata": {
        "id": "6085fa38"
      },
      "source": [
        "## Test data prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2023108e",
      "metadata": {
        "id": "2023108e"
      },
      "source": [
        "###  Gradient Boosting Classifier predicitions and accuracy on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "453f40fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "453f40fd",
        "outputId": "138fdd60-0e0c-4ff0-bcbf-7e8d0ea48602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 tuples of test-predicted data (Actual value, predicted value)\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('suspect', 'suspect')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n"
          ]
        }
      ],
      "source": [
        "GBCFinal.fit(Xtrain, Ytrain)\n",
        "Yguess = GBCFinal.predict(Xtest)\n",
        "print('First 10 tuples of test-predicted data (Actual value, predicted value)')\n",
        "cpt=0\n",
        "for i in zip(Ytest,Yguess):\n",
        "    cpt+=1\n",
        "    if cpt <11:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c6f0e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87c6f0e3",
        "outputId": "e1b49db7-4005-41df-f000-1fa788272bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy of Gradient Boosting: 0.93\n"
          ]
        }
      ],
      "source": [
        "print('Testing accuracy of Gradient Boosting: '+str(round(accuracy_score(Ytest, Yguess),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zJP-71AR9c4Q",
      "metadata": {
        "id": "zJP-71AR9c4Q"
      },
      "source": [
        "###  Random Forest Classifier predicitions and accuracy on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mrJU7zfl9X4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrJU7zfl9X4f",
        "outputId": "3a0440db-b3f7-4c71-c0f1-194f6ae25b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First tuples 10 of test-predicted data (Actual value, predicted value)\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('suspect', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n"
          ]
        }
      ],
      "source": [
        "Yguess = RFCTuned.predict(Xtest)\n",
        "print('First tuples 10 of test-predicted data (Actual value, predicted value)')\n",
        "cpt=0\n",
        "for i in zip(Ytest,Yguess):\n",
        "    cpt+=1\n",
        "    if cpt <11:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8juyD1x890Xq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8juyD1x890Xq",
        "outputId": "8b7cb016-a7f5-4880-9409-136868639155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy of Random Forest: 0.925\n"
          ]
        }
      ],
      "source": [
        "print('Testing accuracy of Random Forest: '+str(round( accuracy_score(Ytest, Yguess),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XfmnhhLF-KJN",
      "metadata": {
        "id": "XfmnhhLF-KJN"
      },
      "source": [
        "###  Decision Tree classifier predicitions and accuracy on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Is3Nh-_-Ni9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Is3Nh-_-Ni9",
        "outputId": "ca311672-20eb-4240-adaa-6feaab62b911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 tuples of test-predicted data (Actual value, predicted value)\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('suspect', 'suspect')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n",
            "('normal', 'normal')\n"
          ]
        }
      ],
      "source": [
        "Yguess = DtTuned.predict(Xtest)\n",
        "print('First 10 tuples of test-predicted data (Actual value, predicted value)')\n",
        "cpt=0\n",
        "for i in zip(Ytest,Yguess):\n",
        "    cpt+=1\n",
        "    if cpt <11:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-R2zZ3oE-QvV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R2zZ3oE-QvV",
        "outputId": "8b09df91-7f2b-4066-8c3a-0a305edb5015",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy of Decision Tree: 0.913\n"
          ]
        }
      ],
      "source": [
        "print('Testing accuracy of Decision Tree: '+str(round( accuracy_score(Ytest, Yguess),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf3df91",
      "metadata": {
        "id": "dbf3df91"
      },
      "source": [
        "From the classifiers above, we can see that the highest scoring classifier is the Random Forest Classifier with a prediction accuracy of 93.7% accuracy on the test set, and a gap of 0.3% between the cv accuracy and the testing accuracy, therefore we know that the classifier is not overfitting the training data, and can be used for future predictions. Recall that a gridsearch was used to tune the hyperparameters of this model to find the values of the hyperparameters as <b>'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 32</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36f6a9fe",
      "metadata": {
        "id": "36f6a9fe"
      },
      "source": [
        "-----------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60a1b992",
      "metadata": {
        "id": "60a1b992"
      },
      "source": [
        "# Implementing a Decision Tree class for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc168424",
      "metadata": {
        "id": "cc168424"
      },
      "outputs": [],
      "source": [
        "class DecisionTreeLeaf:\n",
        "\n",
        "    def __init__(self, value):\n",
        "        self.value = value\n",
        "\n",
        "    # This method computes the prediction for this leaf node. This will just return a constant value.\n",
        "    def predict(self, x):\n",
        "        return self.value\n",
        "\n",
        "    # Utility function to draw a tree visually using graphviz.\n",
        "    def draw_tree(self, graph, node_counter, names):\n",
        "        node_id = str(node_counter)\n",
        "        val_str = f'{self.value:.4g}' if isinstance(self.value, float) else str(self.value)\n",
        "        graph.node(node_id, val_str, style='filled')\n",
        "        return node_counter+1, node_id\n",
        "        \n",
        "    def __eq__(self, other):\n",
        "        if isinstance(other, DecisionTreeLeaf):\n",
        "            return self.value == other.value\n",
        "        else:\n",
        "            return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f3bd19",
      "metadata": {
        "id": "d8f3bd19"
      },
      "outputs": [],
      "source": [
        "class DecisionTreeBranch:\n",
        "\n",
        "    def __init__(self, feature, threshold, low_subtree, high_subtree):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.low_subtree = low_subtree\n",
        "        self.high_subtree = high_subtree\n",
        "\n",
        "    # For a branch node, we compute the prediction by first considering the feature, and then \n",
        "    # calling the upper or lower subtree, depending on whether the feature is or isn't greater\n",
        "    # than the threshold.\n",
        "    def predict(self, x):\n",
        "        if x[self.feature] <= self.threshold:\n",
        "            return self.low_subtree.predict(x)\n",
        "        else:\n",
        "            return self.high_subtree.predict(x)\n",
        "\n",
        "    # Utility function to draw a tree visually using graphviz.\n",
        "    def draw_tree(self, graph, node_counter, names):\n",
        "        node_counter, low_id = self.low_subtree.draw_tree(graph, node_counter, names)\n",
        "        node_counter, high_id = self.high_subtree.draw_tree(graph, node_counter, names)\n",
        "        node_id = str(node_counter)\n",
        "        fname = f'F{self.feature}' if names is None else names[self.feature]\n",
        "        lbl = f'{fname} > {self.threshold:.4g}?'\n",
        "        graph.node(node_id, lbl, shape='box', fillcolor='yellow', style='filled, rounded')\n",
        "        graph.edge(node_id, low_id, 'False')\n",
        "        graph.edge(node_id, high_id, 'True')\n",
        "        return node_counter+1, node_id\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3af38b08",
      "metadata": {
        "id": "3af38b08",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from graphviz import Digraph\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class DecisionTree(ABC, BaseEstimator):\n",
        "\n",
        "    def __init__(self, max_depth):\n",
        "        super().__init__()\n",
        "        self.max_depth = max_depth\n",
        "        \n",
        "    # As usual in scikit-learn, the training method is called *fit*. We first process the dataset so that\n",
        "    # we're sure that it's represented as a NumPy matrix. Then we call the recursive tree-building method\n",
        "    # called make_tree (see below).\n",
        "    def fit(self, X, Y):\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.names = X.columns\n",
        "            X = X.to_numpy()\n",
        "        elif isinstance(X, list):\n",
        "            self.names = None\n",
        "            X = np.array(X)\n",
        "        else:\n",
        "            self.names = None\n",
        "        Y = np.array(Y)        \n",
        "        self.root = self.make_tree(X, Y, self.max_depth)\n",
        "        \n",
        "    def draw_tree(self):\n",
        "        graph = Digraph()\n",
        "        self.root.draw_tree(graph, 0, self.names)\n",
        "        return graph\n",
        "    \n",
        "    # By scikit-learn convention, the method *predict* computes the classification or regression output\n",
        "    # for a set of instances.\n",
        "    # To implement it, we call a separate method that carries out the prediction for one instance.\n",
        "    def predict(self, X):\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.to_numpy()\n",
        "        return [self.predict_one(x) for x in X]\n",
        "\n",
        "    # Predicting the output for one instance.\n",
        "    def predict_one(self, x):\n",
        "        return self.root.predict(x)        \n",
        "\n",
        "    # This is the recursive training \n",
        "    def make_tree(self, X, Y, max_depth):\n",
        "\n",
        "        # We start by computing the default value that will be used if we'll return a leaf node.\n",
        "        # For classifiers, this will be the most common value in Y.\n",
        "        default_value = self.get_default_value(Y)\n",
        "\n",
        "        # First the two base cases in the recursion: is the training set completely\n",
        "        # homogeneous, or have we reached the maximum depth? Then we need to return a leaf.\n",
        "\n",
        "        # If we have reached the maximum depth, return a leaf with the majority value.\n",
        "        if max_depth == 0:\n",
        "            return DecisionTreeLeaf(default_value)\n",
        "\n",
        "        # If all the instances in the remaining training set have the same output value,\n",
        "        # return a leaf with this value.\n",
        "        if self.is_homogeneous(Y):\n",
        "            return DecisionTreeLeaf(default_value)\n",
        "\n",
        "        # Select the \"most useful\" feature and split threshold. To rank the \"usefulness\" of features,\n",
        "        # we use one of the classification or regression criteria.\n",
        "        # For each feature, we call best_split (defined in a subclass). We then maximize over the features.\n",
        "        n_features = X.shape[1]\n",
        "        _, best_feature, best_threshold = max(self.best_split(X, Y, feature) for feature in range(n_features))\n",
        "        \n",
        "        if best_feature is None:\n",
        "            return DecisionTreeLeaf(default_value)\n",
        "\n",
        "        # Split the training set into subgroups, based on whether the selected feature is greater than\n",
        "        # the threshold or not\n",
        "        X_low, X_high, Y_low, Y_high = self.split_by_feature(X, Y, best_feature, best_threshold)\n",
        "\n",
        "        # Build the subtrees using a recursive call. Each subtree is associated\n",
        "        # with a value of the feature.\n",
        "        low_subtree = self.make_tree(X_low, Y_low, max_depth-1)\n",
        "        high_subtree = self.make_tree(X_high, Y_high, max_depth-1)\n",
        "\n",
        "        if low_subtree == high_subtree:\n",
        "            return low_subtree\n",
        "\n",
        "        # Return a decision tree branch containing the result.\n",
        "        return DecisionTreeBranch(best_feature, best_threshold, low_subtree, high_subtree)\n",
        "    \n",
        "    # Utility method that splits the data into the \"upper\" and \"lower\" part, based on a feature\n",
        "    # and a threshold.\n",
        "    def split_by_feature(self, X, Y, feature, threshold):\n",
        "        low = X[:,feature] <= threshold\n",
        "        high = ~low\n",
        "        return X[low], X[high], Y[low], Y[high]\n",
        "    \n",
        "    # The following three methods need to be implemented by the classification and regression subclasses.\n",
        "    \n",
        "    @abstractmethod\n",
        "    def get_default_value(self, Y):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def is_homogeneous(self, Y):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def best_split(self, X, Y, feature):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e18280bf",
      "metadata": {
        "id": "e18280bf"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "class TreeClassifier(DecisionTree, ClassifierMixin):\n",
        "\n",
        "    def __init__(self, max_depth=10, criterion='maj_sum'):\n",
        "        super().__init__(max_depth)\n",
        "        self.criterion = criterion\n",
        "        \n",
        "    def fit(self, X, Y):\n",
        "        # For decision tree classifiers, there are some different ways to measure\n",
        "        # the homogeneity of subsets.\n",
        "        if self.criterion == 'maj_sum':\n",
        "            self.criterion_function = majority_sum_scorer\n",
        "        elif self.criterion == 'info_gain':\n",
        "            self.criterion_function = info_gain_scorer\n",
        "        elif self.criterion == 'gini':\n",
        "            self.criterion_function = gini_scorer\n",
        "        else:\n",
        "            raise Exception(f'Unknown criterion: {self.criterion}')\n",
        "        super().fit(X, Y)\n",
        "        self.classes_ = sorted(set(Y))\n",
        "\n",
        "    # Select a default value that is going to be used if we decide to make a leaf.\n",
        "    # We will select the most common value.\n",
        "    def get_default_value(self, Y):\n",
        "        self.class_distribution = Counter(Y)\n",
        "        return self.class_distribution.most_common(1)[0][0]\n",
        "    \n",
        "    # Checks whether a set of output values is homogeneous. In the classification case, \n",
        "    # this means that all output values are identical.\n",
        "    # We assume that we called get_default_value just before, so that we can access\n",
        "    # the class_distribution attribute. If the class distribution contains just one item,\n",
        "    # this means that the set is homogeneous.\n",
        "    def is_homogeneous(self, Y):\n",
        "        return len(self.class_distribution) == 1\n",
        "        \n",
        "    # Finds the best splitting point for a given feature. We'll keep frequency tables (Counters)\n",
        "    # for the upper and lower parts, and then compute the impurity criterion using these tables.\n",
        "    # In the end, we return a triple consisting of\n",
        "    # - the best score we found, according to the criterion we're using\n",
        "    # - the id of the feature\n",
        "    # - the threshold for the best split\n",
        "    def best_split(self, X, Y, feature):\n",
        "\n",
        "        # Create a list of input-output pairs, where we have sorted\n",
        "        # in ascending order by the input feature we're considering.\n",
        "        sorted_indices = np.argsort(X[:, feature])        \n",
        "        X_sorted = list(X[sorted_indices, feature])\n",
        "        Y_sorted = list(Y[sorted_indices])\n",
        "\n",
        "        n = len(Y)\n",
        "\n",
        "        # The frequency tables corresponding to the parts *before and including*\n",
        "        # and *after* the current element.\n",
        "        low_distr = Counter()\n",
        "        high_distr = Counter(Y)\n",
        "\n",
        "        # Keep track of the best result we've seen so far.\n",
        "        max_score = -np.inf\n",
        "        max_i = None\n",
        "\n",
        "        # Go through all the positions (excluding the last position).\n",
        "        for i in range(0, n-1):\n",
        "\n",
        "            # Input and output at the current position.\n",
        "            x_i = X_sorted[i]\n",
        "            y_i = Y_sorted[i]\n",
        "            \n",
        "            # Update the frequency tables.\n",
        "            low_distr[y_i] += 1\n",
        "            high_distr[y_i] -= 1\n",
        "\n",
        "            # If the input is equal to the input at the next position, we will\n",
        "            # not consider a split here.\n",
        "            #x_next = XY[i+1][0]\n",
        "            x_next = X_sorted[i+1]\n",
        "            if x_i == x_next:\n",
        "                continue\n",
        "\n",
        "            # Compute the homogeneity criterion for a split at this position.\n",
        "            score = self.criterion_function(i+1, low_distr, n-i-1, high_distr)\n",
        "\n",
        "            # If this is the best split, remember it.\n",
        "            if score > max_score:\n",
        "                max_score = score\n",
        "                max_i = i\n",
        "\n",
        "        # If we didn't find any split (meaning that all inputs are identical), return\n",
        "        # a dummy value.\n",
        "        if max_i is None:\n",
        "            return -np.inf, None, None\n",
        "\n",
        "        # Otherwise, return the best split we found and its score.\n",
        "        split_point = 0.5*(X_sorted[max_i] + X_sorted[max_i+1])\n",
        "        return max_score, feature, split_point\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9349e229",
      "metadata": {
        "id": "9349e229"
      },
      "outputs": [],
      "source": [
        "def majority_sum_scorer(n_low, low_distr, n_high, high_distr):\n",
        "    maj_sum_low = low_distr.most_common(1)[0][1]\n",
        "    maj_sum_high = high_distr.most_common(1)[0][1]\n",
        "    return maj_sum_low + maj_sum_high\n",
        "    \n",
        "def entropy(distr):\n",
        "    n = sum(distr.values())\n",
        "    ps = [n_i/n for n_i in distr.values()]\n",
        "    return -sum(p*np.log2(p) if p > 0 else 0 for p in ps)\n",
        "\n",
        "def info_gain_scorer(n_low, low_distr, n_high, high_distr):\n",
        "    return -(n_low*entropy(low_distr)+n_high*entropy(high_distr))/(n_low+n_high)\n",
        "\n",
        "def gini_impurity(distr):\n",
        "    n = sum(distr.values())\n",
        "    ps = [n_i/n for n_i in distr.values()]\n",
        "    return 1-sum(p**2 for p in ps)\n",
        "    \n",
        "def gini_scorer(n_low, low_distr, n_high, high_distr):\n",
        "    return -(n_low*gini_impurity(low_distr)+n_high*gini_impurity(high_distr))/(n_low+n_high)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18dfcd1f",
      "metadata": {
        "id": "18dfcd1f"
      },
      "source": [
        "### tree visualization with small max_depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ef62f5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "6ef62f5f",
        "outputId": "89f9d5ef-e2d0-45b0-f222-cab155e9ab5f",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f3194488290>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"413pt\" height=\"218pt\"\n viewBox=\"0.00 0.00 412.74 218.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 214)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-214 408.7434,-214 408.7434,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"37.6967\" cy=\"-18\" rx=\"37.8943\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"37.6967\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">suspect</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"143.6967\" cy=\"-18\" rx=\"50.0912\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"143.6967\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pathologic</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#ffff00\" stroke=\"#000000\" d=\"M181.6967,-123C181.6967,-123 103.6967,-123 103.6967,-123 97.6967,-123 91.6967,-117 91.6967,-111 91.6967,-111 91.6967,-99 91.6967,-99 91.6967,-93 97.6967,-87 103.6967,-87 103.6967,-87 181.6967,-87 181.6967,-87 187.6967,-87 193.6967,-93 193.6967,-99 193.6967,-99 193.6967,-111 193.6967,-111 193.6967,-117 187.6967,-123 181.6967,-123\"/>\n<text text-anchor=\"middle\" x=\"142.6967\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ALTV &gt; 68.5?</text>\n</g>\n<!-- 2&#45;&gt;0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>2&#45;&gt;0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M120.9406,-86.9735C104.6282,-73.4576 82.2017,-54.8756 64.7359,-40.4039\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"66.5421,-37.3552 56.6088,-33.6701 62.076,-42.7454 66.5421,-37.3552\"/>\n<text text-anchor=\"middle\" x=\"111.6967\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2&#45;&gt;1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>2&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M142.9039,-86.9735C143.0393,-75.1918 143.2189,-59.5607 143.373,-46.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"146.8745,-46.043 143.4897,-36.0034 139.8749,-45.9624 146.8745,-46.043\"/>\n<text text-anchor=\"middle\" x=\"157.1967\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"262.6967\" cy=\"-18\" rx=\"50.0912\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"262.6967\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pathologic</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"367.6967\" cy=\"-18\" rx=\"37.0935\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"367.6967\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">normal</text>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#ffff00\" stroke=\"#000000\" d=\"M303.6967,-123C303.6967,-123 223.6967,-123 223.6967,-123 217.6967,-123 211.6967,-117 211.6967,-111 211.6967,-111 211.6967,-99 211.6967,-99 211.6967,-93 217.6967,-87 223.6967,-87 223.6967,-87 303.6967,-87 303.6967,-87 309.6967,-87 315.6967,-93 315.6967,-99 315.6967,-99 315.6967,-111 315.6967,-111 315.6967,-117 309.6967,-123 303.6967,-123\"/>\n<text text-anchor=\"middle\" x=\"263.6967\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Mean &gt; 107.5?</text>\n</g>\n<!-- 5&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>5&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M263.4895,-86.9735C263.354,-75.1918 263.1744,-59.5607 263.0203,-46.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"266.5184,-45.9624 262.9036,-36.0034 259.5189,-46.043 266.5184,-45.9624\"/>\n<text text-anchor=\"middle\" x=\"278.6967\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 5&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>5&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M285.2455,-86.9735C301.4026,-73.4576 323.6155,-54.8756 340.9149,-40.4039\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"343.5402,-42.771 348.9646,-33.6701 339.0488,-37.4019 343.5402,-42.771\"/>\n<text text-anchor=\"middle\" x=\"335.1967\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#ffff00\" stroke=\"#000000\" d=\"M243.1967,-210C243.1967,-210 162.1967,-210 162.1967,-210 156.1967,-210 150.1967,-204 150.1967,-198 150.1967,-198 150.1967,-186 150.1967,-186 150.1967,-180 156.1967,-174 162.1967,-174 162.1967,-174 243.1967,-174 243.1967,-174 249.1967,-174 255.1967,-180 255.1967,-186 255.1967,-186 255.1967,-198 255.1967,-198 255.1967,-204 249.1967,-210 243.1967,-210\"/>\n<text text-anchor=\"middle\" x=\"202.6967\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">MSTV &gt; 0.45?</text>\n</g>\n<!-- 6&#45;&gt;2 -->\n<g id=\"edge5\" class=\"edge\">\n<title>6&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.2646,-173.9735C181.8175,-161.7252 170.5011,-145.3165 161.0253,-131.5766\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"163.6714,-129.2484 155.1128,-123.0034 157.9089,-133.2226 163.6714,-129.2484\"/>\n<text text-anchor=\"middle\" x=\"191.6967\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 6&#45;&gt;5 -->\n<g id=\"edge6\" class=\"edge\">\n<title>6&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M215.3359,-173.9735C223.9238,-161.7252 235.4288,-145.3165 245.0625,-131.5766\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.1984,-133.2006 251.0736,-123.0034 242.4669,-129.1819 248.1984,-133.2006\"/>\n<text text-anchor=\"middle\" x=\"251.1967\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "cls = TreeClassifier(max_depth=2)\n",
        "cls.fit(Xtrain, Ytrain)\n",
        "cls.draw_tree()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db4a3e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4db4a3e7",
        "outputId": "efe40466-362f-487f-afa5-9e7c393f1f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8685446009389671\n"
          ]
        }
      ],
      "source": [
        "Yguess= cls.predict(Xtest)\n",
        "print(accuracy_score(Ytest,Yguess))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2913941d",
      "metadata": {
        "id": "2913941d"
      },
      "source": [
        "In the tree above, we can see that a small max_depth as 2, resulted in a pretty good testing accuracy of 87% eve though it was intended for tree drawing illustration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "398a9208",
      "metadata": {
        "id": "398a9208"
      },
      "source": [
        "# TreeClassifier model max_depth hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1265836d",
      "metadata": {
        "id": "1265836d",
        "scrolled": true
      },
      "source": [
        "### Tuning using the method using above (max_depth plot vs acuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef3eeab8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ef3eeab8",
        "outputId": "d342a75b-5340-4ff8-cdf5-be52c0c59f12",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hd1Xnn8e9PkmXZ8h2Jm68yl2CHq+0aEickjZMW3ATSSWlwQhpaAqEtNE2ZmdJ5GIYw7TO9pE06M5A8kBA3TApxkjZ1ExraENqQhBDfMIltCI6M74AM8k2yrSOdd/7Y+8hH8pF0JHvrGOn3eR49Ovt2zto+sF6td629liICMzOz3qoqXQAzMzs1OUCYmVlJDhBmZlaSA4SZmZXkAGFmZiXVVLoAJ0tDQ0PMmTOn0sUwM3tDWbt27d6IaCx1bMQEiDlz5rBmzZpKF8PM7A1F0ra+jjnFZGZmJTlAmJlZSQ4QZmZWkgOEmZmVlGmAkHSVpBckbZF0Z4njsyQ9KWm9pOckLUv310r6kqSfStog6Z1ZltPMzI6XWYCQVA3cB1wNzAeWS5rf67S7gJURcRlwPXB/uv9mgIi4CHgP8NeS3NoxMxtGWVa6i4EtEdEcER3Ao8C1vc4JYFL6ejKwO309H/geQES8CuwDFmVYVjMz6yXL5yCmAzuKtncCl/c65x7gXyXdDtQD7073bwCukfQIMBNYmP7+SfHFkm4BbgGYNWvWSS5+T99cv4vmlkOFD+aaS87i3NMnZvqZZmaVVOkH5ZYDKyLiryW9BXhY0oXAQ8A8YA2wDfgR0NX74oh4AHgAYNGiRZktbNHe0cknVz5LBEgQAVtePcj9H16Y1UeamVVclgFiF8lf/QUz0n3FbgKuAoiIpyXVAQ1pWumThZMk/Qj4eYZl7ddLe9uJgPs+tIBfu/gsPvHoen7c/BoRgaRKFcvMLFNZ9kGsBs6T1CSplqQTelWvc7YDSwEkzQPqgBZJ4yXVp/vfA3RGxKYMy9qv5r1JaqmpoR6ABbOm8sqBo+zef6RSRTIzy1xmLYiI6JR0G/A4UA08FBEbJd0LrImIVcAdwIOSPknSYX1jRISk04HHJeVJWh0fyaqc5dja0gYcCxALZ08FYO22VqZPGVexcpmZZSnTPoiIeAx4rNe+u4tebwKWlLjuJeBNWZZtMJr3tnH25DrG1VYDcMGZExk3ppp121q55pKzK1w6M7Ns+NmCMjTvbWNu44Tu7ZrqKi6ZOZm121orWCozs2xVehTTKS8iaG45xPsvnd5j/8LZU/n8fzTT3tHJ+NrK/jNGBH/67c1se619wHOvufTssls967a38vl//wX5AcaHja+t5t5r38yU8bVllfV//cvzNKdpO4APXzGLX37T6T3Oe/Qn2/nu5ldLvsfFMybzB0vPG/gG+tHe0cl//+ZG9h/OndD7mJ0KfmnOVD7+jnNO+vs6QAzgtbYODh7pZG5jfY/9C2dPpSsfPLdzP1fMPa1CpUtse62dL/5gKzOmjmNS3Zg+z9u17zA7Xm8vO0D82bc38/OXDzJz2vg+zwlg854DzG2s5w/fff6A7/nj5td54PvNNDXUM25MNbv3H+bFVw9y5R2NVFclI8Ja2zr41D9vYtK4Gk6rH9vj+oNHc3x38yv86pvP5E1nDv05lK+u3sE31u3kgjMnUuWRaPYG19o+YeCThsABYgDNvTqoCy6beayjutIBYt32JNX1hY8u4oIzJ/V53t9+90U++8TPOXAk128ggeS+1m5r5Z73zefGJU39nnvTitV8+elt3PqOc6gbU93vuQ8+1cxp9bX8yyfeTt2Yah776R5+7yvr+LdNL3PVhWcB8JVntnE418U3f3/JcUGgta2Dt/z5Ezz4VDOfvu6Sfj+rL51deb74g60smj2Vr//uW4f0HmajgfsgBrA1HeJ6TmPPCD21vpa5jfWs3175foi121qZOLaG8wZ4snvh7KlEwLPb9w34nl94qplJdTVct2jmgOfefOVcXm/r4B/W9X7Mpactrx7ke8+/ykfeMrs7kPzqm89k5rRxPPjUVgCOdnax4kfbuPL8xpIthKn1tfzmopn807O7ePXA0IYZP77xFXa2HuZjb587pOvNRgsHiAE0t7RRW13F2SWGsy6cNZW121qJyOwh7rKs3dbKpbOmdKdo+nLJzMlUiQE717e91sZ3Nr7MDVfMpn7swI3My5umcdH0yXzhqWby/XRYfOGprYytqeIjV8zu3lddJW5a0tTdYvmn9bvZe+got/RTef/OkiY688GKH700YNl6iwgeeKqZOaeN5z3zzxj09WajiQPEAJr3tjH7tPElK9+Fs6fS2p5j6962ElcOj4NHcvz8lYMsmDV1wHMn1o3hTWdO6k5J9eWhH2ylpkp89K1zyiqDJD729iaa97bxvedLdyy3HDzKP6zfxQcWzuC0CT37Fa5bNJNJdTU8+P1mHnyqmQvOnMiSc/tO281pqOdX55/JV57ZTtvRzrLKWLBmWysbduzjprc1DRhQzUY7B4gBNLccOq6DumBB0QNzlbJhx37ycezhvYEsmDWFZ7fvo6uPv/T3tXewcs1Orr10OmdMqiu7HMsuOovpU8bxwFPNJY8//PRL5Lry3PS24/sz6sfWcMMVs/nOxpd58dVD3HLl3AGnMLn5yrnsP5zja2t29Htebw98v5mp48fwGwsHTp2ZjXbupO5HZ1ee7a+38575Z5Y8fm7jBCbW1XDvtzbx2e++CMB1i2aUNZrnZFm7rRUJLp01pazzF86eylee2c6Lrx7s7tB+8PvN3emao51dHM518bG3998x3duY6ip+e8kc/vTbm1ny59877njLwaMsveCM4/pyCj761jk8+FQz0+pree/FA4+yWjh7KgtmTeHPv/N8d/9FOXbvP8xtv3xu90OPZtY3B4h+7Gw9TK4r+mxBVFWJu987nx83vw7A6pde55837B7WALFueyvnnz5xwFFJBcXThFxw5iQOHMnxt0+8yIyp43jz2ZOB5Enx/kZD9eVDl89ix+vtHDp63MS7VFfBLVf23a9wxqQ6/vw/XUzDxLHU1pTXsL3nmjfz5ae3MZguoLoxVSVbMWZ2PAeIfhT6FuY2lA4QkOTPCyN9/uI7z/OFp5rp7MpTU5199i6fD9Ztby3rL+6CWdPG0zChlrXbWvnw5bN59CfbOXS0k09fdwkXTp98QuUZX1vDp669cMjXf2DhjEGdf/GMKXz6uvJaTmY2eO6D6Mcv0gWC5vaRFumtqaGeXFews/VwlsXqtqXlEAePdJbd/wBJh/KCWVNZv30fua48X/rhS7xl7mknHBzMbORxgOjH1r1tTB43hqnjy0vfnJOmooZrVNO6tHN8MAECks71rXvb+PLT29iz/wg3X+mUi5kdzwGiH80tbcxtrC97UaCmhqSlUWh5ZG3ttlam1dcy57S+p8IopRBQ/urx5zn39Am88/zTB7jCzEYjB4h+bN3bdtwUG/2ZVl/LlPFjTnoLoq8H8dZub2XBrCmDXtXuoumTGVMtjuTyfOxtTVT5eQAzK8EBog+HO7p4+cCRfjuoS2lqqO8xU+mJam45xEX3/Otxz1q8vP8IzS1tXFbGA3K91Y2p5sLpk2mYUMv7L5s+8AVmNio5QPRh76GjAJw+sfyHxQDmNkw4qS2IjbsPcOhoJ/c/uaXH/hU/eokqwfsGMYKp2F984GJW/PbiASfXM7PRywGiD/vak3UCppTZQV0wt7Gelw8cGfQUEH3Zsz8ZEfXE86+y5dWkb+PQ0U7+/pltXHXhmcwaZP9DwflnTPTIJTPrlwNEH15v7wCSfoXBKKSkTlYrYs/+I4ytqaK2poov/iCZxmLl6h0cONLJzZ6N1Mwy5ADRh31pgChnlbRiTelQ1+aTFSD2HWHmtPF8YMEMvrFuF68cOMJDP0zWMhhK/4OZWbkyDRCSrpL0gqQtku4scXyWpCclrZf0nKRl6f4xkv5O0k8lbZb0J1mWs5TWtiRAlPsMRMGc0+qRYOtJ6qjes/8wZ02u46a3NdHRmefmL69hZ+thbu5n2gozs5MhswAhqRq4D7gamA8slzS/12l3ASsj4jLgeuD+dP91wNiIuAhYCHxc0pysylpKa9oHMXnc4AJE3Zhqzp48jua9x56FaO/oHPLiNrv3H+HsyeM49/QJvHve6Ty3cz9zThvPu+d5LQMzy1aWLYjFwJaIaI6IDuBR4Npe5wRQmBVuMrC7aH+9pBpgHNABHMiwrMfZ197BpLqaIc2pNLexvkcfxB0rN/Dr9/9o0AsLdXTm2XvoKGdNSUZS3XJlsij5zVfO9VoGZpa5LAPEdKB4sv6d6b5i9wA3SNoJPAbcnu7/OtAG7AG2A5+OiNd7f4CkWyStkbSmpaXlpBb+9fbcoDuoC+amz0JEBFv3Jquz7dp3eNBzNL1y4AgRcPbkZDW7xU3T+O4fvYMPLZ41pHKZmQ1GpTuplwMrImIGsAx4WFIVSeujCzgbaALukHRc0j0iHoiIRRGxqLGx8aQWbF97x6A7qAuaGuo5dLSTlkNH+eIPmrunox7swkK79yUBpdCCADj39AmDfnLazGwosgwQu4DiZbtmpPuK3QSsBIiIp4E6oAH4EPCdiMhFxKvAD4FFGZb1OK3tHYPuoC4ozP669qVWvrZmJx9YMIP62upBB4g9+5N+i7MmD+5hPTOzkyHLALEaOE9Sk6Rakk7oVb3O2Q4sBZA0jyRAtKT735XurweuAJ7PsKzHaW3LMfUEWhCQrA9xtDPPre+Yy6WzppxAgBg3pHKYmZ2IzAJERHQCtwGPA5tJRittlHSvpGvS0+4Abpa0AXgEuDGSntz7gAmSNpIEmi9FxHNZlbWU1vYOpg6xD2L6lHHU1lTx0mvt/PKbGjnvjIksnDWV518+MKgnrPfsP8ykuhrqx3pdJzMbfpnWPBHxGEnnc/G+u4tebwKWlLjuEMlQ14o42tlFe0fXkFNMVVWi6bR6XnjlYPfTzpfNnko+YMOOfbz13Iay3mf3viOcPcWtBzOrjEp3Up+Sjs3DNLQWBMAvNU1l8ZxpvOWc0wBYMPPYWtDlKjwkZ2ZWCc5dlNDaXniKeugB4n9eeyERdI84mjx+DOedPoF12wcTII5wyUyvuWxmleEWRAmvF6bZqB9aigmSwNB7IZ6Fs6eybvs+8vmBH5g7kuvi9bYOznYLwswqxAGihEKK6URaEKUsmDWV/YdzPabh6ItHMJlZpTlAlHAyUkylLJhdfj/EnsJDcm5BmFmFOECUMNTFggYyt6GeKePHsG7bvgHP7W5BeBSTmVWIA0QJr7d1ML62+qQvx1lVJRbMmsqabcdNK3WcwkpybkGYWaU4QJSQTLNxctNLBfPPmsTWvW10DdBRvXv/EabV13rNaDOrGAeIEva15056eqmgceJY8nFspFRf9uzzMxBmVlkOECVk2YJomDAWgL2HjvZ73p79RzyCycwqygGihNa2oc/DNJCGCcn7DhQgdu87zNlT3IIws8pxgCihtT035HmYBtIwceAWRNvRTg4c6XQLwswqygGil658cOBI7oTmYepPd4rpYN99EIURTG5BmFklOUD0sv9wjggya0FMqquhtrqq3xZEYWnSMyc5QJhZ5ThA9FIYXTTU9agHIomGCbW09BMgVj27m/G11cw7e1ImZTAzK4cDRC/70mk2skoxQdIPsfdQ6RTTnv2HWbVhNx/8pZlMqsumFWNmVg4HiF5auyfqy65ybpwwlr0HS7cgVvzwJfIR/M6Spsw+38ysHA4QvWQ1UV+xhgljS6aYDh7J8ffPbOfqi85i5rTxmX2+mVk5HCB6ae1eCyLLFFMtr7d1HLcuxFdX7+Dg0U5uSZcpNTOrJAeIXlrbc4ypFvW12c2B1DBhLF356G6tAHR25fnSD19i8ZxpXkXOzE4JmQYISVdJekHSFkl3ljg+S9KTktZLek7SsnT/hyU9W/STl3RplmUt2NfewZTxtd1LhWbh2HQbxwLE955/lV37DvOxt7vvwcxODZkFCEnVwH3A1cB8YLmk+b1OuwtYGRGXAdcD9wNExFci4tKIuBT4CLA1Ip7NqqzFknmYsh09VGo+pp/t2k+V4J1vOj3TzzYzK1eWLYjFwJaIaI6IDuBR4Npe5wRQGOw/Gdhd4n2Wp9cOi9a2XKYd1ACNE4+fj6l5bxszp42ntsZZPzM7NWRZG00HdhRt70z3FbsHuEHSTuAx4PYS7/NB4JFSHyDpFklrJK1paWk58RKT7UyuBYUWREvRUNfmljbmNtRn+rlmZoNR6T9XlwMrImIGsAx4WFJ3mSRdDrRHxM9KXRwRD0TEoohY1NjYeFIK1NqeY2p9timmyePGMKZa3X0Q+XywdW8bTQ0TMv1cM7PByDJA7AJmFm3PSPcVuwlYCRARTwN1QEPR8evpo/WQhYjo7qTOkiROqx/bnWJ65eARDue6mNvoFoSZnTqyDBCrgfMkNUmqJansV/U6ZzuwFEDSPJIA0ZJuVwG/yTD2Pxw82klnPjLvpIbkWYhCgGhuaQNwisnMTimZBYiI6ARuAx4HNpOMVtoo6V5J16Sn3QHcLGkDSUvhxogoPD12JbAjIpqzKmNv+9NpNqaMy7YFAel0G4UAsTcNEI1OMZnZqaMmyzePiMdIOp+L991d9HoTsKSPa/8duCLL8vV2tDMPwNgx2XfNNEwYy+Y9BwFobjnE+Npqzpg0NvPPNTMrV6U7qU8pua4kQNRWD0OAmDiW19qOElHooK7P9OE8M7PBcoAoUggQY4YjQEwYS64r2H84R3NLEiDMzE4lDhBFcl1J98eYYXhYrWFC0s+xa99hdra2u//BzE45DhBFjrUgsk/1NKYPy63b1ko+PILJzE49DhBFhjXFNDEJEM9sfR3Az0CY2SnHAaLIcPdBAKx+KQkQ7oMws1ONA0SR7j6IYUgxTRk3huoq8cqBozROHMtErz9tZqcYB4giwznMtapKnJauWufWg5mdihwgihQCRM0wBAiAxrQf4hz3P5jZKcgBokiuc/hSTHCsH8ItCDM7FTlAFOkYxhQTHAsQcz3Nt5mdghwginQO4ygmSGZ0BWhyisnMTkEOEEUKo5hqhinFtHjONC6eMZlZ08YPy+eZmQ1GprO5vtF0DHMLYum8M1g674xh+Swzs8FyC6LIcD4oZ2Z2qnNNWKSzK6iuEtVVnnbbzGzAACHpfenynyNeris/bENczcxOdeVU/B8EXpT0l5IuyLpAldTRlWdM1aiIhWZmAxqwNoyIG4DLgF8AKyQ9LekWSRMzL90wy3Xlh2UtCDOzN4KyasOIOAB8HXgUOAv4dWCdpNszLNuw6+wKp5jMzFLl9EFcI+kfgX8HxgCLI+Jq4BLgjgGuvUrSC5K2SLqzxPFZkp6UtF7Sc5KWFR27OG2tbJT0U0l1g725weroynsEk5lZqpznID4AfCYivl+8MyLaJd3U10WSqoH7gPcAO4HVklZFxKai0+4CVkbE5yTNBx4D5kiqAf4f8JGI2CDpNCA3qDsbglxXOECYmaXKqQ3vAX5S2JA0TtIcgIh4op/rFgNbIqI5IjpI0lPX9jongEnp68nA7vT1rwDPRcSG9HNei4iuMsp6QnKdHsVkZlZQToD4GpAv2u5K9w1kOrCjaHtnuq/YPcANknaStB4KfRrnAyHpcUnrJP3XUh+QdpavkbSmpaWljCL1L+cUk5lZt3Jqw5q0BQBA+rr2JH3+cmBFRMwAlgEPp89c1ABvAz6c/v51SUt7XxwRD0TEoohY1NjYeMKFyeWdYjIzKyinNmyRdE1hQ9K1wN4yrtsFzCzanpHuK3YTsBIgIp4G6oAGktbG9yNib0S0k7QuFpTxmSfEKSYzs2PKCRC3Av9N0nZJO4A/Bj5exnWrgfMkNUmqBa4HVvU6ZzuwFEDSPJIA0QI8DlwkaXzaYf0OYBMZc4rJzOyYAUcxRcQvgCskTUi3D5XzxhHRKek2ksq+GngoIjZKuhdYExGrSIbJPijpkyQd1jdGRACtkv6GJMgE8FhEfHsI9zcoua489WM9wa2ZGZQ53bekXwPeDNRJSQomIu4d6LqIeIwkPVS87+6i15uAJX1c+/9IhroOGw9zNTM7ppwH5T5PMh/T7YCA64DZGZerInJdeWpr3AdhZgbl9UG8NSJ+C2iNiE8BbyEZhjri5Lry1HiyPjMzoLwAcST93S7pbJInms/KrkiV4xSTmdkx5fRB/LOkKcBfAetIOo0fzLRUFeIUk5nZMf0GiPShtSciYh/wDUnfAuoiYv+wlG6YeZirmdkx/daGEZEnmXCvsH10pAYHSFJM7oMwM0uUUxs+IekDKoxvHcE6uvKMcYrJzAwoL0B8nGRyvqOSDkg6KOlAxuWqiFxXnlqnmMzMgPKepB5xS4uW0pUPInAfhJlZasAAIenKUvt7LyD0RpfrSmY0d4AwM0uUM8z1vxS9riNZCGgt8K5MSlQhHd0Bwn0QZmZQXorpfcXbkmYCn82sRBWS63QLwsys2FBqw53AvJNdkErrzAfgAGFmVlBOH8T/IXl6GpKAcinJE9UjSkenU0xmZsXK6YNYU/S6E3gkIn6YUXkqxp3UZmY9lRMgvg4ciYguAEnVksanS4GOGLkup5jMzIqV9SQ1MK5oexzw3WyKUzk5j2IyM+uhnABRV7zMaPp6fHZFqozuAFHjFoSZGZQXINokLShsSFoIHM6uSJXRnWLyZH1mZkB5fRB/CHxN0m6SJUfPJFmCdERxisnMrKcB/1yOiNXABcDvArcC8yJibTlvLukqSS9I2iLpzhLHZ0l6UtJ6Sc9JWpbunyPpsKRn05/PD+62Bq/DKSYzsx4GrA0l/T5QHxE/i4ifARMk/V4Z11WTrCVxNTAfWC5pfq/T7gJWRsRlwPXA/UXHfhERl6Y/t5Z5P0PWmaaYPJurmVminNrw5nRFOQAiohW4uYzrFgNbIqI5IjqAR4Fre50TwKT09WRgdxnvmwk/B2Fm1lM5tWF18WJBacugtozrpgM7irZ3pvuK3QPcIGkn8Bhwe9GxpjT19B+S3l7qAyTdImmNpDUtLS1lFKlvhQBR4z4IMzOgvADxHeCrkpZKWgo8AvzLSfr85cCKiJgBLAMeTtfB3gPMSlNPfwT8vaRJvS+OiAciYlFELGpsbDyhghSm2nCKycwsUc4opj8GbiHpoAZ4jmQk00B2ATOLtmek+4rdBFwFEBFPS6oDGiLiVeBoun+tpF8A59Nz2o+TypP1mZn1VM4opjzwDPASSb/Cu4DNZbz3auA8SU2Sakk6oVf1Omc7sBRA0jyS9SZaJDWmqSwkzQXOA5rLuaGh8jBXM7Oe+mxBSDqfJAW0HNgLfBUgIn65nDeOiE5JtwGPA9XAQxGxUdK9wJqIWAXcATwo6ZMkHdY3RkSkq9jdKykH5IFbI+L1Id9lGQopphq3IMzMgP5TTM8DTwHvjYgtAGlFXraIeIyk87l4391FrzcBS0pc9w3gG4P5rBOV8zBXM7Me+qsN/xNJZ/GTkh5MO6hHbP6l0ykmM7Me+gwQEfHNiLie5CnqJ0mm3Dhd0uck/cpwFXC45LrySFBd5QBhZgbldVK3RcTfp2tTzwDWk4xsGlE6uoIxVVUUPfJhZjaqDSrhHhGt6bMHS7MqUKXkuvJOL5mZFXGPbCrXlfdEfWZmRVwjpnJd4YfkzMyKuEZM5bryHuJqZlbENWIq15X3RH1mZkUcIFJJJ7X/OczMClwjptwHYWbWk2vEVNIH4RSTmVmBA0Qq6YPwP4eZWYFrxFSuM/ygnJlZEQeIVC7vTmozs2KuEVN+DsLMrCfXiKkkxeR/DjOzAteIKT8oZ2bWkwNEqsMpJjOzHlwjpjr9oJyZWQ+uEVPJdN9OMZmZFWQaICRdJekFSVsk3Vni+CxJT0paL+k5SctKHD8k6T9nWU5IUkw1VY6XZmYFmdWIkqqB+4CrgfnAcknze512F7AyIi4Drgfu73X8b4B/yaqMxXJdeWq9YJCZWbcsa8TFwJaIaI6IDuBR4Npe5wQwKX09GdhdOCDp/cBWYGOGZeyW9EE4xWRmVpBlgJgO7Cja3pnuK3YPcIOkncBjwO0AkiYAfwx8qr8PkHSLpDWS1rS0tAy5oPl80Jl3J7WZWbFK14jLgRURMQNYBjwsqYokcHwmIg71d3FEPBARiyJiUWNj45ALkcvnARwgzMyK1GT43ruAmUXbM9J9xW4CrgKIiKcl1QENwOXAb0j6S2AKkJd0JCL+bxYFzXUFgFNMZmZFsgwQq4HzJDWRBIbrgQ/1Omc7sBRYIWkeUAe0RMTbCydIugc4lFVwAMh1ugVhZtZbZjViRHQCtwGPA5tJRittlHSvpGvS0+4Abpa0AXgEuDEiIqsy9cUpJjOz42XZgiAiHiPpfC7ed3fR603AkgHe455MClekkGLyVBtmZse4RuRYismT9ZmZHeMAQfKQHDjFZGZWzDUixaOY/M9hZlbgGpFjLYhaT9ZnZtbNAYJjAcKT9ZmZHeMakWQmV3CKycysmGtEkon6wCkmM7NiDhB4FJOZWSmuEXEfhJlZKa4RgQ6nmMzMjuMAgSfrMzMrxTUi0OnJ+szMjuMakWMpJgcIM7NjXCNSnGJyH4SZWYEDBB7mamZWimtEoDPvFJOZWW+uEYEOp5jMzI7jAEGSYqqpEpIDhJlZgQMESYBwesnMrCfXiiQLBjm9ZGbWU6YBQtJVkl6QtEXSnSWOz5L0pKT1kp6TtCzdv1jSs+nPBkm/nmU5c115amscK83MitVk9caSqoH7gPcAO4HVklZFxKai0+4CVkbE5yTNBx4D5gA/AxZFRKeks4ANkv45IjqzKKtTTGZmx8uyVlwMbImI5ojoAB4Fru11TgCT0teTgd0AEdFeFAzq0vMyk+sKapxiMjPrIcsAMR3YUbS9M91X7B7gBkk7SVoPtxcOSLpc0kbgp8CtWbUeIFlRzi0IM7OeKl0rLgdWRMQMYBnwsKQqgIh4JiLeDPwS8CeS6npfLOkWSWskrWlpaRlyITq78tQ6QJiZ9ZBlrbgLmFm0PSPdV+wmYCVARDxNkk5qKD4hIjYDh4ALe39ARDwQEYsiYlFjY+OQC5qMYnKAMDMrlmWtuPdB6w4AAAlASURBVBo4T1KTpFrgemBVr3O2A0sBJM0jCRAt6TU16f7ZwAXAS1kVNNeVdx+EmVkvmY1iSkcg3QY8DlQDD0XERkn3AmsiYhVwB/CgpE+SdETfGBEh6W3AnZJyQB74vYjYm1VZOzrdB2Fm1ltmAQIgIh4j6Xwu3nd30etNwJIS1z0MPJxl2Yp15oNxY6qH6+PMzN4Q/GczhecgnGIyMyvmAEGSYqpxisnMrAfXiqRTbThAmJn14FqRpA/CKSYzs54cIEjWpPYoJjOznlwrAh1dwRjP5mpm1oNrRdJRTFVOMZmZFXOAwNN9m5mV4loR6HSKyczsOKO+VowIT/dtZlbCqK8VO/PJWkTugzAz62nUB4hcVx7AKSYzs15Gfa2Y60pbEE4xmZn1MOprxUILotZPUpuZ9eAAkQYIT9ZnZtbTqK8Vc51OMZmZlTLqa8VcPu2kdorJzKwHB4juPohR/09hZtbDqK8VnWIyMytt1NeKE+pq+LWLzuLMyXWVLoqZ2Skl0wAh6SpJL0jaIunOEsdnSXpS0npJz0lalu5/j6S1kn6a/n5XVmVsaqjnvg8v4MLpk7P6CDOzN6SarN5YUjVwH/AeYCewWtKqiNhUdNpdwMqI+Jyk+cBjwBxgL/C+iNgt6ULgcWB6VmU1M7PjZdmCWAxsiYjmiOgAHgWu7XVOAJPS15OB3QARsT4idqf7NwLjJI3NsKxmZtZLZi0Ikr/4dxRt7wQu73XOPcC/SrodqAfeXeJ9PgCsi4ijWRTSzMxKq3Qn9XJgRUTMAJYBD0vqLpOkNwN/AXy81MWSbpG0RtKalpaWYSmwmdlokWWA2AXMLNqeke4rdhOwEiAingbqgAYASTOAfwR+KyJ+UeoDIuKBiFgUEYsaGxtPcvHNzEa3LAPEauA8SU2SaoHrgVW9ztkOLAWQNI8kQLRImgJ8G7gzIn6YYRnNzKwPmQWIiOgEbiMZgbSZZLTSRkn3SromPe0O4GZJG4BHgBsjItLrzgXulvRs+nN6VmU1M7PjKamP3/gWLVoUa9asqXQxzMzeUCStjYhFJY+NlAAhqQXYNohLGkietxhtRuN9j8Z7htF536PxnuHE7nt2RJTsxB0xAWKwJK3pK2qOZKPxvkfjPcPovO/ReM+Q3X1XepirmZmdohwgzMyspNEcIB6odAEqZDTe92i8Zxid9z0a7xkyuu9R2wdhZmb9G80tCDMz64cDhJmZlTQqA8RACxmNBJJmposxbZK0UdIn0v3TJP2bpBfT31MrXdYsSKpOF6L6VrrdJOmZ9Dv/ajr9y4ghaYqkr0t6XtJmSW8ZDd+1pE+m/33/TNIjkupG4nct6SFJr0r6WdG+kt+vEv87vf/nJC0Y6ueOugBRtJDR1cB8YHm6WNFI0wncERHzgSuA30/v807giYg4D3gi3R6JPkEyxUvBXwCfiYhzgVaSiSJHkr8FvhMRFwCXkNz7iP6uJU0H/gBYFBEXAtUkc76NxO96BXBVr319fb9XA+elP7cAnxvqh466AEF5Cxm94UXEnohYl74+SFJhTCe5179LT/s74P2VKWF20pmAfw34Qrot4F3A19NTRtR9S5oMXAl8ESAiOiJiH6PguyZZ02acpBpgPLCHEfhdR8T3gdd77e7r+70W+HIkfgxMkXTWUD53NAaIUgsZjejlTCXNAS4DngHOiIg96aGXgTMqVKwsfRb4r0A+3T4N2JdOIAkj7ztvAlqAL6VptS9IqmeEf9cRsQv4NMms0HuA/cBaRvZ3Xayv7/ek1XGjMUCMKpImAN8A/jAiDhQfS2fOHVHjnCW9F3g1ItZWuizDqAZYAHwuIi4D2uiVThqh3/VUkr+Wm4CzSVal7J2GGRWy+n5HY4AoZyGjEUHSGJLg8JWI+Id09yuF5mb6+9VKlS8jS4BrJL1Ekj58F0l+fkqahoCR953vBHZGxDPp9tdJAsZI/67fDWyNiJaIyAH/QPL9j+Tvulhf3+9Jq+NGY4AoZyGjN7w07/5FYHNE/E3RoVXAR9PXHwX+abjLlqWI+JOImBERc0i+2+9FxIeBJ4HfSE8bUfcdES8DOyS9Kd21FNjECP+uSVJLV0gan/73XrjvEftd99LX97sK+K10NNMVwP6iVNSgjMonqSUtI8lTVwMPRcSfVbhIJ52ktwFPAT/lWC7+v5H0Q6wEZpFMj/6bEdG782tEkPRO4D9HxHslzSVpUUwD1gM3RMTRSpbvZJJ0KUmnfC3QDPw2yR+AI/q7lvQp4IMko/bWAx8jybePqO9a0iPAO0mm9X4F+B/ANynx/abB8v+SpNvagd+OiCEtljMqA4SZmQ1sNKaYzMysDA4QZmZWkgOEmZmV5ABhZmYlOUCYmVlJDhA2akk6TdKz6c/LknYVbZ/0GUAl/bukIS0sL+n9xZNKnsh7mZWrZuBTzEamiHgNuBRA0j3AoYj4dOG4pJqiOX0q7f3At0geBDMbFm5BmBWRtELS5yU9A/ylpHMkfUfSWklPSbogPa9R0jckrU5/lpR4r3GSHk3XZ/hHYFzRsV+R9LSkdZK+ls6ZhaSXJP2lpJ9K+omkcyW9FbgG+Ku0dXNO+jbXpef8XNLbM//HsVHHLQiz480A3hoRXZKeAG6NiBclXQ7cz7H5nT4TET+QNAt4HJjX631+F2iPiHmSLgbWAUhqAO4C3h0RbZL+GPgj4N70uv0RcZGk3wI+mz4Jvgr4VkR8PX0PgJqIWJzODPA/SOYmMjtpHCDMjve1NDhMAN4KfC2tkAHGpr/fDcwv2j9J0oSIOFT0PlcC/xsgIp6T9Fy6/wqSxap+mF5fCzxddN0jRb8/0085CxMwrgXmlH13ZmVygDA7Xlv6u4pkbYFLS5xTBVwREUeG8P4C/i0ilvdxPPp43VthfqEu/P+yZcB9EGZ9SNfP2CrpOuhe6/eS9PC/ArcXzk0ny+vt+8CH0uMXAhen+38MLJF0bnqsXtL5Rdd9sOh3oWVxEJh4wjdlNggOEGb9+zBwk6QNwEaOLU/7B8AiJYvCbwJuLXHt54AJkjaT9C+sBYiIFuBG4JE07fQ0cEHRdVPT/Z8APpnuexT4L+mKcedgNgw8m6vZKSRd6GhRROytdFnM3IIwM7OS3IIwM7OS3IIwM7OSHCDMzKwkBwgzMyvJAcLMzEpygDAzs5L+Py5KDkNqFo4eAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "max_depths = np.linspace(1, 100, 100, endpoint=True)\n",
        "\n",
        "test_results = []\n",
        "for max_depth in max_depths:\n",
        "    dt = TreeClassifier(max_depth=max_depth)\n",
        "    dt.fit(Xtrain, Ytrain)\n",
        "    Ypred = dt.predict(Xtest)\n",
        "    accuracyTemp = accuracy_score(Ytest, Ypred)\n",
        "\n",
        "    test_results.append(accuracyTemp)\n",
        "line= plt.plot(max_depths, test_results, label='Test accuracy')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Tree depth')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7a0680",
      "metadata": {
        "id": "7e7a0680"
      },
      "source": [
        "by searching the space of [1,100] max_depth we found that max_depth = 7 maximizes the accuracy of the TreeClassifier when the only used parameter is max_depth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e687acc",
      "metadata": {
        "id": "4e687acc"
      },
      "source": [
        "### Tuning using sklearn gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec83ab11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec83ab11",
        "outputId": "a0629ed2-9297-4561-ccc8-0f6f6a217a21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=TreeClassifier(), n_jobs=-1,\n",
              "             param_grid={'criterion': ['gini', 'maj_sum', 'info_gain'],\n",
              "                         'max_depth': [3, 5, 7, 10, 40, 70, 100]})"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "dTgridTuned = TreeClassifier()\n",
        "parameter_space = {'max_depth': [3,5,7,10,40,70,100],\n",
        "                'criterion': ['gini','maj_sum','info_gain']}\n",
        "DtTuned = GridSearchCV(dTgridTuned, parameter_space, n_jobs=-1, cv=5)\n",
        "DtTuned.fit(Xtrain, Ytrain) # X is train samples and y is the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b1f0700",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b1f0700",
        "outputId": "fe2de093-59a2-4077-ac60-ad472953d2f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini', 'max_depth': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "DtTuned.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6706be18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6706be18",
        "outputId": "71bc7eda-ffb4-4026-c637-95e3e4231bc2",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.934705882352941"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "DTFinal = TreeClassifier(max_depth=7,criterion='gini')\n",
        "cross_val_score(DTFinal, Xtrain, Ytrain).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e6efcb3",
      "metadata": {
        "id": "0e6efcb3"
      },
      "source": [
        "by tuning the model TreeClassifier with a range of different values for max_depth and different types of splitting criterion, we found that the parameters that maximizes the classifier's accuracy are max_depth=7 and criterion = gini impurity which gives us a cross validation accuracy of 93.5% "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1de40c8",
      "metadata": {
        "id": "e1de40c8"
      },
      "source": [
        "## TreeClassifier evaluation on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3815f241",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3815f241",
        "outputId": "a5181646-fd42-47e2-897f-809d68fa562a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy of the TreeClassifier model is:  0.913\n"
          ]
        }
      ],
      "source": [
        "DTFinal = TreeClassifier(max_depth=7,criterion='gini')\n",
        "DTFinal.fit(Xtrain, Ytrain)\n",
        "Yguess = DTFinal.predict(Xtest)\n",
        "print('The testing accuracy of the TreeClassifier model is: ',round(accuracy_score(Ytest, Yguess),3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b81f82c",
      "metadata": {
        "id": "1b81f82c"
      },
      "source": [
        "By testing the classifier, we got a testing accuracy of 91% by using the hyperparameter <b>max_depth = 7</b> and <b>criterion = 'gini'</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f78b2a7",
      "metadata": {
        "id": "5f78b2a7"
      },
      "source": [
        "-----------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "592d1543",
      "metadata": {
        "id": "592d1543"
      },
      "source": [
        "# Regressors applications in ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9f53fc9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "9f53fc9a",
        "outputId": "e20d9850-315d-4833-e803-0301535e1f01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id   timestamp  full_sq  life_sq  floor  max_floor  material  build_year  \\\n",
              "0   1  2011-08-20       43     27.0    4.0        NaN       NaN         NaN   \n",
              "1   2  2011-08-23       34     19.0    3.0        NaN       NaN         NaN   \n",
              "2   3  2011-08-27       43     29.0    2.0        NaN       NaN         NaN   \n",
              "3   4  2011-09-01       89     50.0    9.0        NaN       NaN         NaN   \n",
              "4   5  2011-09-05       77     77.0    4.0        NaN       NaN         NaN   \n",
              "\n",
              "   num_room  kitch_sq  ...  cafe_count_5000_price_2500  \\\n",
              "0       NaN       NaN  ...                           9   \n",
              "1       NaN       NaN  ...                          15   \n",
              "2       NaN       NaN  ...                          10   \n",
              "3       NaN       NaN  ...                          11   \n",
              "4       NaN       NaN  ...                         319   \n",
              "\n",
              "  cafe_count_5000_price_4000 cafe_count_5000_price_high  \\\n",
              "0                          4                          0   \n",
              "1                          3                          0   \n",
              "2                          3                          0   \n",
              "3                          2                          1   \n",
              "4                        108                         17   \n",
              "\n",
              "   big_church_count_5000  church_count_5000  mosque_count_5000  \\\n",
              "0                     13                 22                  1   \n",
              "1                     15                 29                  1   \n",
              "2                     11                 27                  0   \n",
              "3                      4                  4                  0   \n",
              "4                    135                236                  2   \n",
              "\n",
              "   leisure_count_5000  sport_count_5000  market_count_5000  price_doc  \n",
              "0                   0                52                  4    5850000  \n",
              "1                  10                66                 14    6000000  \n",
              "2                   4                67                 10    5700000  \n",
              "3                   0                26                  3   13100000  \n",
              "4                  91               195                 14   16331452  \n",
              "\n",
              "[5 rows x 292 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4b4293f-e207-42e4-9ba9-47674985c789\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>full_sq</th>\n",
              "      <th>life_sq</th>\n",
              "      <th>floor</th>\n",
              "      <th>max_floor</th>\n",
              "      <th>material</th>\n",
              "      <th>build_year</th>\n",
              "      <th>num_room</th>\n",
              "      <th>kitch_sq</th>\n",
              "      <th>...</th>\n",
              "      <th>cafe_count_5000_price_2500</th>\n",
              "      <th>cafe_count_5000_price_4000</th>\n",
              "      <th>cafe_count_5000_price_high</th>\n",
              "      <th>big_church_count_5000</th>\n",
              "      <th>church_count_5000</th>\n",
              "      <th>mosque_count_5000</th>\n",
              "      <th>leisure_count_5000</th>\n",
              "      <th>sport_count_5000</th>\n",
              "      <th>market_count_5000</th>\n",
              "      <th>price_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-08-20</td>\n",
              "      <td>43</td>\n",
              "      <td>27.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>5850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-08-23</td>\n",
              "      <td>34</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>66</td>\n",
              "      <td>14</td>\n",
              "      <td>6000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-08-27</td>\n",
              "      <td>43</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>10</td>\n",
              "      <td>5700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-09-01</td>\n",
              "      <td>89</td>\n",
              "      <td>50.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>13100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-09-05</td>\n",
              "      <td>77</td>\n",
              "      <td>77.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>319</td>\n",
              "      <td>108</td>\n",
              "      <td>17</td>\n",
              "      <td>135</td>\n",
              "      <td>236</td>\n",
              "      <td>2</td>\n",
              "      <td>91</td>\n",
              "      <td>195</td>\n",
              "      <td>14</td>\n",
              "      <td>16331452</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 292 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4b4293f-e207-42e4-9ba9-47674985c789')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4b4293f-e207-42e4-9ba9-47674985c789 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4b4293f-e207-42e4-9ba9-47674985c789');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Read the CSV file using Pandas.\n",
        "alldata = pd.read_csv('//content//drive//MyDrive//Data//sberbank.csv')\n",
        "alldata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4c74b5dc",
      "metadata": {
        "id": "4c74b5dc",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Convert the timestamp string to an integer representing the year.\n",
        "def get_year(timestamp):\n",
        "    return int(timestamp[:4])\n",
        "alldata['year'] = alldata.timestamp.apply(get_year)\n",
        "\n",
        "# Select the 9 input columns and the output column.\n",
        "selected_columns = ['price_doc', 'year', 'full_sq', 'life_sq', 'floor', 'num_room', 'kitch_sq', 'full_all']\n",
        "alldata = alldata[selected_columns]\n",
        "alldata = alldata.dropna()\n",
        "\n",
        "# Shuffle.\n",
        "alldata_shuffled = alldata.sample(frac=1.0, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ac3b9671",
      "metadata": {
        "id": "ac3b9671"
      },
      "outputs": [],
      "source": [
        "# Separate the input and output columns.\n",
        "X = alldata_shuffled.drop('price_doc', axis=1)\n",
        "# For the output, we'll use the log of the sales price.\n",
        "Y = alldata_shuffled['price_doc'].apply(np.log)\n",
        "\n",
        "# Split into training and test sets.\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f56aca9c",
      "metadata": {
        "id": "f56aca9c"
      },
      "source": [
        "# Dummy Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff921699",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff921699",
        "outputId": "6398dd57-4972-44a6-cd8d-ac03eac8661a",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38925247260237567"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "m1 = DummyRegressor()\n",
        "cross_validate(m1, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86c8d177",
      "metadata": {
        "id": "86c8d177"
      },
      "source": [
        "By cross-validation the dummy classifier on the training data's different fold, we get a mean square error of 0.39 in predicting   the price of an apartment, given numerical information such as the number of rooms, the size of the apartment in square meters, the floor."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72d29ec1",
      "metadata": {
        "id": "72d29ec1"
      },
      "source": [
        "# Linear models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "175d6cd9",
      "metadata": {
        "id": "175d6cd9"
      },
      "source": [
        "We firstly start by experimenting the Linear Regression of sklearn on our training data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e11764",
      "metadata": {
        "id": "85e11764"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2cd5f25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2cd5f25",
        "outputId": "5cbdc2c2-f7c6-4ace-fe0b-389e00a958e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30139865887671935"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "ligr = LinearRegression()\n",
        "cross_validate(ligr, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f833623",
      "metadata": {
        "id": "2f833623"
      },
      "source": [
        "By cross-validation the Linear Regression on the training data's different folds, we get an average mean square error of 0.301 between the different folds of the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b84368d",
      "metadata": {
        "id": "4b84368d"
      },
      "source": [
        "### Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "232e0364",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "232e0364",
        "outputId": "5d7b56ae-3df5-4433-e106-11526e23930c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3013978423217977"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "rid = Ridge()\n",
        "cross_validate(rid, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0e3a1cd",
      "metadata": {
        "id": "f0e3a1cd"
      },
      "source": [
        "As we can see, the Ridge model obtained an average cross-validation mean squared error  of 0.301 between the different folds of the training set, so we proceed by tuning the Ridge model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "010efb2b",
      "metadata": {
        "id": "010efb2b"
      },
      "source": [
        "### tuning Ridge model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b261e2",
      "metadata": {
        "id": "56b261e2"
      },
      "outputs": [],
      "source": [
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# define grid\n",
        "model = Ridge()\n",
        "grid = dict()\n",
        "grid['alpha'] = arange(0,50000,1000)\n",
        "# define search\n",
        "search = GridSearchCV(model, grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
        "# perform the search\n",
        "RidgeTuned = search.fit(Xtrain, Ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c87c5f18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c87c5f18",
        "outputId": "fe6fd74f-100c-40f4-c919-4d66280aea6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30542683118598124\n",
            "{'alpha': 49000}\n"
          ]
        }
      ],
      "source": [
        "print(RidgeTuned.best_score_*-1)\n",
        "print(RidgeTuned.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c647c3",
      "metadata": {
        "id": "83c647c3"
      },
      "source": [
        "By tuning Ridge model with L2 penalty lamda (alpha in the code) of different values in a sequence of values of [0,1000,...,50000], we found that Rigde model with the value lambda (alpha) equal to 49000 had mean squared error of 0.3 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f560a776",
      "metadata": {
        "id": "f560a776"
      },
      "source": [
        "### Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b365e8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b365e8d",
        "outputId": "496ee302-f62e-48d5-d19d-5ba54bba3c38",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3010470671748872"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "lasso = Lasso()\n",
        "cross_validate(lasso, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cef4c2",
      "metadata": {
        "id": "d6cef4c2"
      },
      "source": [
        "In Lasso model, we also got an average (mean squared error) of 0.301 by cross validation between the different folds of the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "532adde7",
      "metadata": {
        "id": "532adde7"
      },
      "source": [
        "#### Lasso tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9a5f99",
      "metadata": {
        "id": "8c9a5f99"
      },
      "outputs": [],
      "source": [
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "lasso_alphas = arange(0, 0.1,10)\n",
        "lasso = Lasso()\n",
        "grid = dict()\n",
        "grid['alpha'] = lasso_alphas\n",
        "\n",
        "search = GridSearchCV(lasso, grid, scoring='neg_mean_squared_error',cv=cv, n_jobs=-1)\n",
        "lassoTuned = search.fit(Xtrain, Ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e06e2f01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e06e2f01",
        "outputId": "74cda898-9c99-4bac-f0f8-66583889e3a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3089324957581782\n",
            "{'alpha': 0.0}\n"
          ]
        }
      ],
      "source": [
        "print(lassoTuned.best_score_*-1)\n",
        "print(lassoTuned.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705ddd77",
      "metadata": {
        "id": "705ddd77"
      },
      "source": [
        "By tuning the model using a gridsearch, the gridsearch found that the best L1 penalty lambda (alpha) = 0 which resulted in a MSE of 0.308"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b068f31",
      "metadata": {
        "id": "9b068f31"
      },
      "source": [
        "# Tree regressors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0274109",
      "metadata": {
        "id": "b0274109"
      },
      "source": [
        "### Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eda39e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eda39e5",
        "outputId": "dd3f5423-c11e-412e-c473-2c97ba18a092"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5311698007009944"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "dtr = DecisionTreeRegressor()\n",
        "cross_validate(dtr, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f612585",
      "metadata": {
        "id": "1f612585"
      },
      "source": [
        "As we can see, the Decision Tree Regressor obtained an average cross-validation mean squared error of 0.522 between the different folds of the training data, so we proceed by tuning the Decision Tree Regressor model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2945283",
      "metadata": {
        "id": "f2945283"
      },
      "source": [
        "### Tuning decision tree regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcc827ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcc827ba",
        "outputId": "b291e96f-9cc2-4d0f-a9b9-1c904febd686"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
              "             param_grid={'criterion': ['squared_error', 'friedman_mse',\n",
              "                                       'absolute_error', 'poisson'],\n",
              "                         'max_depth': [3, 5, 10, 40, 70, 100]})"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "### Tuning using sklearn gridsearch\n",
        "dTrgridTuned = DecisionTreeRegressor()\n",
        "parameter_space = {'max_depth': [3,5,10,40,70,100],\n",
        "                'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']\n",
        "                  }\n",
        "DtTuned = GridSearchCV(dTrgridTuned, parameter_space, n_jobs=-1, cv=5)\n",
        "DtTuned.fit(Xtrain, Ytrain) # X is train samples and y is the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33c4e7e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33c4e7e2",
        "outputId": "a7169f00-dc7e-4f2a-97ff-659a7b800f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'friedman_mse', 'max_depth': 5}\n",
            "0.27328343498173957\n"
          ]
        }
      ],
      "source": [
        "print(DtTuned.best_params_)\n",
        "print(DtTuned.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85dbc6b5",
      "metadata": {
        "id": "85dbc6b5"
      },
      "source": [
        "By tuning the Decision tree regressor model on the parameters<b> max_depth</b> and <b> criterion</b>, we found that the hyperparameters values that minimizes the model's MSE are <b> max_depth = 5</b> and <b> creterion = 'friedman_mse'</b> which resulted in a MSE value of 0.27 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb30f5a0",
      "metadata": {
        "id": "eb30f5a0"
      },
      "source": [
        "### Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50e9fbaa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50e9fbaa",
        "outputId": "61ab6ca0-e1e8-4cc4-89be-e6cded189990"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2659229822429888"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "regr = RandomForestRegressor(max_depth=10, random_state=0)\n",
        "cross_validate(regr, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1### Tuning decision tree regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c256d0b4",
      "metadata": {
        "id": "c256d0b4"
      },
      "source": [
        "In the Random Forest Regressor obtained an average cross-validation mean squared error of 0.266, so we then proceed by tuning the Random Forest Regressor model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc7d15e",
      "metadata": {
        "id": "1dc7d15e"
      },
      "source": [
        "### Tuning Random Forest regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc92b463",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc92b463",
        "outputId": "f99dafd1-d629-46b1-8f95-30b7bbdfa50f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
              "             param_grid={'max_depth': [5, 10, 70], 'n_estimators': [100, 500]})"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# ### Tuning using sklearn gridsearch\n",
        "RfRgridTuned = RandomForestRegressor()\n",
        "parameter_space = {'max_depth': [5,10,70],\n",
        "                  'n_estimators' : [100,500]}\n",
        "RFRTuned = GridSearchCV(RfRgridTuned, parameter_space, n_jobs=-1, cv=5)\n",
        "RFRTuned.fit(Xtrain, Ytrain) # X is train samples and y is the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a4b1227",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a4b1227",
        "outputId": "7bc83174-00c2-415c-c281-66fc67a841e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 10, 'n_estimators': 500}\n",
            "0.31672038496764093\n"
          ]
        }
      ],
      "source": [
        "print(RFRTuned.best_params_)\n",
        "print(RFRTuned.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9263681",
      "metadata": {
        "id": "b9263681"
      },
      "source": [
        "By tuning the Random forest regressor model on the parameters<b> max_depth</b> and <b>n_estimators</b> , we found that the hyperparameters values that minimizes the model's MSE are <b> max_depth = 10</b> and <b> n_estimators = 500</b> which resulted in a MSE value of 0.317 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64d6f885",
      "metadata": {
        "id": "64d6f885"
      },
      "source": [
        "### Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3d41a01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3d41a01",
        "outputId": "f7972605-2fc6-48c9-e3b9-edff203da535"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26452609782146225"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "gbr = GradientBoostingRegressor()\n",
        "cross_validate(gbr, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5683c0d2",
      "metadata": {
        "id": "5683c0d2"
      },
      "source": [
        "The Gradient Boosting Regressor obtained an average cross-validation mean squared error of 0.265, so we then proceed by tuing the Gradient Boosting Regressor model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e78ad397",
      "metadata": {
        "id": "e78ad397"
      },
      "source": [
        "### Gradient boosting tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "216c1666",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "216c1666",
        "outputId": "4f0d1b2a-a873-44eb-d410-29828122a7e5",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
              "             param_grid={'alpha': [0.0001, 0.001, 0.01],\n",
              "                         'criterion': ['mse', 'friedman_mse']})"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "GBRgridTuned = GradientBoostingRegressor()\n",
        "parameter_space = {\n",
        "    # 'loss' : ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
        "    # 'n_estimators' : [ 2, 4, 8, 16, 32, 64, 100, 200,500]\n",
        "                'criterion': ['mse','friedman_mse'], #'mae','squared_error',  \n",
        "                  'alpha': [0.0001,0.001,0.01 ]}\n",
        "GBRTuned = GridSearchCV(GBRgridTuned, parameter_space, n_jobs=-1, cv=5)\n",
        "GBRTuned.fit(Xtrain, Ytrain) # X is train samples and y is the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5fb4521",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5fb4521",
        "outputId": "4c5c0c0a-971d-4026-b6aa-d18f4e41648d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'alpha': 0.01, 'criterion': 'mse'}\n",
            "0.31982142169500416\n"
          ]
        }
      ],
      "source": [
        "print(GBRTuned.best_params_)\n",
        "print(GBRTuned.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "470309ba",
      "metadata": {
        "id": "470309ba"
      },
      "source": [
        "By tuning the Gradient boosting on the parameters alpha and criterion, we found that the hyperparameters values that minimizes the model's MSE are \n",
        "<b>creterion = 'friedman_mse'</b> and <b>alpha = 0.001 </b>and which resulted in a MSE value of <b>0.32</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c31e588",
      "metadata": {
        "id": "8c31e588"
      },
      "source": [
        "### MLP Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6454a030",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6454a030",
        "outputId": "da3a3e5b-4120-4b2a-eb49-13fef309ed1b",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "280045.12368458847"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "mlp = MLPRegressor()\n",
        "cross_validate(mlp, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7058da71",
      "metadata": {
        "id": "7058da71"
      },
      "source": [
        "The MLP Regressor obtained an average cross-validation mean squared error of 24, so we then proceed by tuing the MLP model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cf33977",
      "metadata": {
        "id": "2cf33977"
      },
      "source": [
        "### Tuning MLP regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2b8b998",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2b8b998",
        "outputId": "1e901c3d-04bd-48d7-8759-dbb8edc313e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=MLPRegressor(), n_jobs=-1,\n",
              "             param_grid={'activation': ['relu', 'logistic'],\n",
              "                         'hidden_layer_sizes': [(150,), (1000,)]})"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "mlpRgridTuned = MLPRegressor()\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(150,),(1000,)],#,(3000,)\n",
        "    'activation': ['relu','logistic'],#'tanh', \n",
        "    # 'solver': ['lbfgs', 'sgd','adam'],\n",
        "    # 'alpha': [0.0001,0.001,0.01,0.1,1],\n",
        "    # 'learning_rate': ['constant','invscaling', 'adaptive']\n",
        "}\n",
        "mlpTuned = GridSearchCV(mlpRgridTuned, parameter_space, n_jobs=-1, cv=5)\n",
        "mlpTuned.fit(Xtrain, Ytrain) # X is train samples and y is the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a323f3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a323f3b",
        "outputId": "3c3540a5-077a-452f-e8c8-aec7cfdfaeb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'activation': 'logistic', 'hidden_layer_sizes': (1000,)}\n",
            "0.019712852395943826\n"
          ]
        }
      ],
      "source": [
        "print(mlpTuned.best_params_)\n",
        "print(mlpTuned.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3afcaebb",
      "metadata": {
        "id": "3afcaebb"
      },
      "source": [
        "By tuning the MLP on the parameters alpha and criterion, we found that the hyperparameters values that minimizes the model's MSE are \n",
        "<b>activation = 'logistic'</b> and <b>hidden_layer_sizes = (1000,)</b>and which resulted in a MSE value of <b>0.022</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2e722e",
      "metadata": {
        "id": "6c2e722e"
      },
      "source": [
        "# Models evaluation and test set prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca928351",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca928351",
        "outputId": "c19a454d-91d8-436c-e673-bcda6d896acf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regressors cross-validation mean squared error report: \n",
            "\n",
            "\n",
            "Dummy Regressor: 0.38925247260237567\n",
            "\n",
            "\n",
            "Decision Tree Regressor: 0.27328343498173957\n",
            "\n",
            "\n",
            "Random Forest Regressor: 0.2659229822429888\n",
            "\n",
            "\n",
            "Gradient Boosting Regressor: 0.264547471807441\n",
            "\n",
            "\n",
            "Ridge Regressor: 0.30542683118598124\n",
            "\n",
            "\n",
            "Lasso Regressor: 0.3089324957581782\n",
            "\n",
            "\n",
            "Linear Regression: 0.30139865887671935\n",
            "\n",
            "\n",
            "MLP Regressor: 0.019712852395943826\n"
          ]
        }
      ],
      "source": [
        "print(\"Regressors cross-validation mean squared error report: \")\n",
        "print('\\n')\n",
        "print(\"Dummy Regressor:\", cross_validate(m1, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1)\n",
        "print('\\n')\n",
        "print(\"Decision Tree Regressor:\", DtTuned.best_score_)\n",
        "print('\\n')\n",
        "print(\"Random Forest Regressor:\", cross_validate(regr, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1)\n",
        "print('\\n')\n",
        "print(\"Gradient Boosting Regressor:\", cross_validate(gbr, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1)\n",
        "print('\\n')\n",
        "print(\"Ridge Regressor:\", RidgeTuned.best_score_*-1)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Lasso Regressor:\",lassoTuned.best_score_*-1)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Linear Regression:\", cross_validate(ligr, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score'].mean()*-1)\n",
        "\n",
        "print('\\n')\n",
        "print(\"MLP Regressor:\", mlpTuned.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06b1f05a",
      "metadata": {
        "id": "06b1f05a"
      },
      "source": [
        "## Best performing models predictions of the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad71c503",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad71c503",
        "outputId": "506f2414-5e2d-4a68-ef65-7d48a4d25655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Regressor: \n",
            "MSE: 0.40445556539321104\n"
          ]
        }
      ],
      "source": [
        "# predictions using MLP NN\n",
        "# mlpTuned.fit(Xtrain,Ytrain)\n",
        "Yguess = mlpTuned.predict(Xtest)\n",
        "print('MLP Regressor: ')\n",
        "print( 'MSE: '+str(mean_squared_error(Ytest,Yguess)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac0e51f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ac0e51f",
        "outputId": "74fcc187-f3a2-4aa5-d34a-ff82c8f850c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest Regressor: \n",
            "MSE: 0.2740850405500036\n"
          ]
        }
      ],
      "source": [
        "# predictions using RandomForest Regressor\n",
        "regr.fit(Xtrain,Ytrain)\n",
        "Yguess = regr.predict(Xtest)\n",
        "print('RandomForest Regressor: ')\n",
        "print( 'MSE: '+str(mean_squared_error(Ytest,Yguess)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "733a1a56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "733a1a56",
        "outputId": "9666a8e0-634a-4622-d093-d95ed76c6b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor: \n",
            "MSE: 0.27141423140462584\n"
          ]
        }
      ],
      "source": [
        "# predictions using Gradient Boosting Regressor\n",
        "gbr.fit(Xtrain,Ytrain)\n",
        "Yguess = gbr.predict(Xtest)\n",
        "print('Gradient Boosting Regressor: ')\n",
        "print( 'MSE: '+str(mean_squared_error(Ytest,Yguess)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6935c75f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6935c75f",
        "outputId": "9ed5cf71-9799-4a25-aee6-5141e3eaf1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor: \n",
            "MSE: 0.290835267309146\n"
          ]
        }
      ],
      "source": [
        "# predictions using DecisionTree Regressor\n",
        "Yguess = DtTuned.predict(Xtest)\n",
        "print('Decision Tree Regressor: ')\n",
        "print( 'MSE: '+str(mean_squared_error(Ytest,Yguess)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7842a906",
      "metadata": {
        "id": "7842a906"
      },
      "source": [
        "By testing the best performing models in the cross validation phase with predicting the test set, the best performing model in predicting the testing set was the Gradient boosting regressor which predicted the testing set with a mean squared error of approximately 0.27 with a difference of +0.01 in the MSE than its cross-validation accuracy, the model was tuned using  gridsearch to find that the hyperparameters that minimizes the mse are <b>alpha= 0.001 and criterion = 'friedman_mse' </b>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86df3959",
      "metadata": {
        "id": "86df3959"
      },
      "source": [
        "# Implementing a Decision Tree class for regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "21303a61",
      "metadata": {
        "id": "21303a61"
      },
      "outputs": [],
      "source": [
        "class DecisionTreeLeaf:\n",
        "\n",
        "    def __init__(self, value):\n",
        "        self.value = value\n",
        "\n",
        "    # This method computes the prediction for this leaf node. This will just return a constant value.\n",
        "    def predict(self, x):\n",
        "        return self.value\n",
        "\n",
        "    # Utility function to draw a tree visually using graphviz.\n",
        "    def draw_tree(self, graph, node_counter, names):\n",
        "        node_id = str(node_counter)\n",
        "        val_str = f'{self.value:.4g}' if isinstance(self.value, float) else str(self.value)\n",
        "        graph.node(node_id, val_str, style='filled')\n",
        "        return node_counter+1, node_id\n",
        "        \n",
        "    def __eq__(self, other):\n",
        "        if isinstance(other, DecisionTreeLeaf):\n",
        "            return self.value == other.value\n",
        "        else:\n",
        "            return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "57de035b",
      "metadata": {
        "id": "57de035b"
      },
      "outputs": [],
      "source": [
        "class DecisionTreeBranch:\n",
        "\n",
        "    def __init__(self, feature, threshold, low_subtree, high_subtree):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.low_subtree = low_subtree\n",
        "        self.high_subtree = high_subtree\n",
        "\n",
        "    # For a branch node, we compute the prediction by first considering the feature, and then \n",
        "    # calling the upper or lower subtree, depending on whether the feature is or isn't greater\n",
        "    # than the threshold.\n",
        "    def predict(self, x):\n",
        "        if x[self.feature] <= self.threshold:\n",
        "            return self.low_subtree.predict(x)\n",
        "        else:\n",
        "            return self.high_subtree.predict(x)\n",
        "\n",
        "    # Utility function to draw a tree visually using graphviz.\n",
        "    def draw_tree(self, graph, node_counter, names):\n",
        "        node_counter, low_id = self.low_subtree.draw_tree(graph, node_counter, names)\n",
        "        node_counter, high_id = self.high_subtree.draw_tree(graph, node_counter, names)\n",
        "        node_id = str(node_counter)\n",
        "        fname = f'F{self.feature}' if names is None else names[self.feature]\n",
        "        lbl = f'{fname} > {self.threshold:.4g}?'\n",
        "        graph.node(node_id, lbl, shape='box', fillcolor='yellow', style='filled, rounded')\n",
        "        graph.edge(node_id, low_id, 'False')\n",
        "        graph.edge(node_id, high_id, 'True')\n",
        "        return node_counter+1, node_id\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "97df0c02",
      "metadata": {
        "id": "97df0c02",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "class DecisionTree(ABC, BaseEstimator):\n",
        "\n",
        "    def __init__(self, max_depth):\n",
        "        super().__init__()\n",
        "        self.max_depth = max_depth\n",
        "        \n",
        "    # As usual in scikit-learn, the training method is called *fit*. We first process the dataset so that\n",
        "    # we're sure that it's represented as a NumPy matrix. Then we call the recursive tree-building method\n",
        "    # called make_tree (see below).\n",
        "    def fit(self, X, Y):\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.names = X.columns\n",
        "            X = X.to_numpy()\n",
        "        elif isinstance(X, list):\n",
        "            self.names = None\n",
        "            X = np.array(X)\n",
        "        else:\n",
        "            self.names = None\n",
        "        Y = np.array(Y)        \n",
        "        self.root = self.make_tree(X, Y, self.max_depth)\n",
        "        \n",
        "    def draw_tree(self):\n",
        "        graph = Digraph()\n",
        "        self.root.draw_tree(graph, 0, self.names)\n",
        "        return graph\n",
        "    \n",
        "    # By scikit-learn convention, the method *predict* computes the classification or regression output\n",
        "    # for a set of instances.\n",
        "    # To implement it, we call a separate method that carries out the prediction for one instance.\n",
        "    def predict(self, X):\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.to_numpy()\n",
        "        return [self.predict_one(x) for x in X]\n",
        "\n",
        "    # Predicting the output for one instance.\n",
        "    def predict_one(self, x):\n",
        "        return self.root.predict(x)        \n",
        "\n",
        "    # This is the recursive training \n",
        "    def make_tree(self, X, Y, max_depth):\n",
        "\n",
        "        # We start by computing the default value that will be used if we'll return a leaf node.\n",
        "        # For classifiers, this will be the most common value in Y.\n",
        "        default_value = self.get_default_value(Y)\n",
        "\n",
        "        # First the two base cases in the recursion: is the training set completely\n",
        "        # homogeneous, or have we reached the maximum depth? Then we need to return a leaf.\n",
        "\n",
        "        # If we have reached the maximum depth, return a leaf with the majority value.\n",
        "        if max_depth == 0:\n",
        "            return DecisionTreeLeaf(default_value)\n",
        "\n",
        "        # If all the instances in the remaining training set have the same output value,\n",
        "        # return a leaf with this value.\n",
        "        if self.is_homogeneous(Y):\n",
        "            return DecisionTreeLeaf(default_value)\n",
        "\n",
        "        # Select the \"most useful\" feature and split threshold. To rank the \"usefulness\" of features,\n",
        "        # we use one of the classification or regression criteria.\n",
        "        # For each feature, we call best_split (defined in a subclass). We then maximize over the features.\n",
        "        n_features = X.shape[1]\n",
        "        _, best_feature, best_threshold = max(self.best_split(X, Y, feature) for feature in range(n_features))\n",
        "        \n",
        "        if best_feature is None:\n",
        "            return DecisionTreeLeaf(default_value)\n",
        "\n",
        "        # Split the training set into subgroups, based on whether the selected feature is greater than\n",
        "        # the threshold or not\n",
        "        X_low, X_high, Y_low, Y_high = self.split_by_feature(X, Y, best_feature, best_threshold)\n",
        "\n",
        "        # Build the subtrees using a recursive call. Each subtree is associated\n",
        "        # with a value of the feature.\n",
        "        low_subtree = self.make_tree(X_low, Y_low, max_depth-1)\n",
        "        high_subtree = self.make_tree(X_high, Y_high, max_depth-1)\n",
        "\n",
        "        if low_subtree == high_subtree:\n",
        "            return low_subtree\n",
        "\n",
        "        # Return a decision tree branch containing the result.\n",
        "        return DecisionTreeBranch(best_feature, best_threshold, low_subtree, high_subtree)\n",
        "    \n",
        "    # Utility method that splits the data into the \"upper\" and \"lower\" part, based on a feature\n",
        "    # and a threshold.\n",
        "    def split_by_feature(self, X, Y, feature, threshold):\n",
        "        low = X[:,feature] <= threshold\n",
        "        high = ~low\n",
        "        return X[low], X[high], Y[low], Y[high]\n",
        "    \n",
        "    # The following three methods need to be implemented by the classification and regression subclasses.\n",
        "    \n",
        "    @abstractmethod\n",
        "    def get_default_value(self, Y):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def is_homogeneous(self, Y):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def best_split(self, X, Y, feature):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "772a3b04",
      "metadata": {
        "id": "772a3b04"
      },
      "outputs": [],
      "source": [
        "class TreeRegressor(DecisionTree, RegressorMixin):\n",
        "\n",
        "    def __init__(self, max_depth=10, threshold = 0.2,  criterion='var_red'):\n",
        "        super().__init__(max_depth)\n",
        "        self.criterion = criterion\n",
        "        self.threshold = threshold\n",
        "        \n",
        "        \n",
        "    def fit(self, X, Y):\n",
        "        # For decision tree classifiers, there are some different ways to measure\n",
        "        # the homogeneity of subsets.\n",
        "        if self.criterion == 'var_red':\n",
        "            self.criterion_function = variance_reduction_scorer\n",
        "        else:\n",
        "            raise Exception(f'Unknown criterion: {self.criterion}')\n",
        "        super().fit(X, Y)\n",
        "        self.classes_ = sorted(set(Y))\n",
        "\n",
        "    # Select a default value that is going to be used if we decide to make a leaf.\n",
        "    # We will select the most common value.\n",
        "    def get_default_value(self, Y):\n",
        "        return np.mean(Y)\n",
        "    \n",
        "    # Checks whether a set of output values is homogeneous. In the classification case, \n",
        "    # this means that all output values are identical.\n",
        "    # We assume that we called get_default_value just before, so that we can access\n",
        "    # the class_distribution attribute. If the class distribution contains just one item,\n",
        "    # this means that the set is homogeneous.\n",
        "    def is_homogeneous(self, Y):\n",
        "        return np.var(Y) <= self.threshold #threshold (set to be 0.2 through trial and error to minimize the mse)\n",
        "        \n",
        "    # Finds the best splitting point for a given feature. We'll keep frequency tables (Counters)\n",
        "    # for the upper and lower parts, and then compute the impurity criterion using these tables.\n",
        "    # In the end, we return a triple consisting of\n",
        "    # - the best score we found, according to the criterion we're using\n",
        "    # - the id of the feature\n",
        "    # - the threshold for the best split\n",
        "    def best_split(self, X, Y, feature):\n",
        "\n",
        "        # Create a list of input-output pairs, where we have sorted\n",
        "        # in ascending order by the input feature we're considering.\n",
        "        sorted_indices = np.argsort(X[:, feature])        \n",
        "        X_sorted = list(X[sorted_indices, feature])\n",
        "        Y_sorted = list(Y[sorted_indices])\n",
        "\n",
        "        n = len(Y)\n",
        "        \n",
        "        \n",
        "        # declaring the 2 subsets of the feature as empty list and the full list before entering the loop\n",
        "        low_distr = []\n",
        "        high_distr = Y_sorted\n",
        "        \n",
        "        # Keep track of the best result we've seen so far.\n",
        "        max_score = -np.inf\n",
        "        max_i = None\n",
        "\n",
        "        total_sum = sum(Y_sorted)\n",
        "        total_sum_square = sum([y ** 2 for y in Y_sorted])\n",
        "        total_var = total_sum_square/n - (total_sum ** 2)/(n ** 2)\n",
        "\n",
        "        # Go through all the positions (excluding the last position).\n",
        "        for i in range(0, n-1):\n",
        "\n",
        "            # Input and output at the current position.\n",
        "            x_i = X_sorted[i]\n",
        "            y_i = Y_sorted[i]\n",
        "\n",
        "            \n",
        "            # Update the frequency tables.\n",
        "#             low_distr[y_i] += 1\n",
        "#             high_distr[y_i] -= 1\n",
        "            \n",
        "            #low_distr subset is the output variable items before the current instance, and \n",
        "            #high_distr subset is the output variable items from and after the current instance, and \n",
        "            low_distr =  Y_sorted[0:i]    \n",
        "            high_distr = Y_sorted[i:]\n",
        "\n",
        "            # If the input is equal to the input at the next position, we will\n",
        "            # not consider a split here.\n",
        "            #x_next = XY[i+1][0]\n",
        "            x_next = X_sorted[i+1]\n",
        "            if x_i == x_next:\n",
        "                continue\n",
        "                \n",
        "\n",
        "            # Compute the homogeneity criterion for a split at this position.\n",
        "            score = self.criterion_function(i+1, low_distr, n-i-1, high_distr)\n",
        "\n",
        "            # If this is the best split, remember it.\n",
        "            if score > max_score:\n",
        "                max_score = score\n",
        "                max_i = i\n",
        "\n",
        "        # If we didn't find any split (meaning that all inputs are identical), return\n",
        "        # a dummy value.\n",
        "        if max_i is None:\n",
        "            return -np.inf, None, None\n",
        "\n",
        "        # Otherwise, return the best split we found and its score.\n",
        "        split_point = 0.5*(X_sorted[max_i] + X_sorted[max_i+1])\n",
        "        return max_score, feature, split_point\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bcc17d70",
      "metadata": {
        "id": "bcc17d70"
      },
      "outputs": [],
      "source": [
        "def variance_reduction_scorer(n_low, low_distr, n_high, high_distr): \n",
        "    return np.var(low_distr + high_distr) - n_low/(n_low+n_high)*np.var(high_distr) - n_high/(n_low+n_high)*np.var(low_distr)\n",
        "\n",
        "def majority_sum_scorer(n_low, low_distr, n_high, high_distr):\n",
        "    maj_sum_low = low_distr.most_common(1)[0][1]\n",
        "    maj_sum_high = high_distr.most_common(1)[0][1]\n",
        "    return maj_sum_low + maj_sum_high\n",
        "    \n",
        "def entropy(distr):\n",
        "    n = sum(distr.values())\n",
        "    ps = [n_i/n for n_i in distr.values()]\n",
        "    return -sum(p*np.log2(p) if p > 0 else 0 for p in ps)\n",
        "\n",
        "def info_gain_scorer(n_low, low_distr, n_high, high_distr):\n",
        "    return -(n_low*entropy(low_distr)+n_high*entropy(high_distr))/(n_low+n_high)\n",
        "\n",
        "def gini_impurity(distr):\n",
        "    n = sum(distr.values())\n",
        "    ps = [n_i/n for n_i in distr.values()]\n",
        "    return 1-sum(p**2 for p in ps)\n",
        "    \n",
        "def gini_scorer(n_low, low_distr, n_high, high_distr):\n",
        "    return -(n_low*gini_impurity(low_distr)+n_high*gini_impurity(high_distr))/(n_low+n_high)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f89eb64",
      "metadata": {
        "id": "0f89eb64"
      },
      "source": [
        "1. To define the threshold, instead of setting it to a constant value that might not maximize the model's accuracy, we added a new parameter <b> threshold</b> to the init function of the model with a default value threshold = 0.2, so we can add it to the gridsearch later on, so we can get the best threshold for the homogenity of the set by the variance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4fab414",
      "metadata": {
        "id": "b4fab414"
      },
      "source": [
        "2. To select a default value that is going to be used if we decide to make a leaf, we select the mean value of the output variable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ad65820",
      "metadata": {
        "id": "9ad65820"
      },
      "source": [
        "3. The split that leads to the highest homogenity is selected by calculating the variance reduction function of the 2 subsets of the output variable at each observation and taking the split with the highest homogenity score, to do that, we declared the function <i>variance_reduction_scorer(n_low, low_distr, n_high, high_distr)</i>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "29ba6b4e",
      "metadata": {
        "id": "29ba6b4e"
      },
      "outputs": [],
      "source": [
        "dtr = TreeRegressor(max_depth=5)\n",
        "dtr.fit(Xtrain, Ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4467c4b0",
      "metadata": {
        "id": "4467c4b0"
      },
      "outputs": [],
      "source": [
        "Yguess = dtr.predict(Xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b690223e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b690223e",
        "outputId": "cd7440fa-5c97-45eb-87a8-02f805f9432e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4027607081960747"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "  \n",
        "mean_squared_error(Ytest,Yguess)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34a0c900",
      "metadata": {
        "id": "34a0c900"
      },
      "source": [
        "we then use the class Tree Regressor to predict the testing set, and we get a mean squared error of 0.4 on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5556167",
      "metadata": {
        "id": "e5556167"
      },
      "source": [
        "## Tuning TressRegressor hyperparameters with gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4fe06899",
      "metadata": {
        "id": "4fe06899",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# # define grid\n",
        "# model = TreeRegressor()\n",
        "# grid = dict()\n",
        "# grid['max_depth'] = [6,12]\n",
        "# grid['threshold'] = [0.1,0.2,0.3]\n",
        "\n",
        "# # define search\n",
        "# search = GridSearchCV(model, grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
        "# # perform the search\n",
        "# results = search.fit(Xtrain, Ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2ce76200",
      "metadata": {
        "id": "2ce76200"
      },
      "outputs": [],
      "source": [
        "# results.best_params_\n",
        "# results.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "737aa16b",
      "metadata": {
        "id": "737aa16b"
      },
      "source": [
        "### TreeRegressorer model max_depth hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7274617",
      "metadata": {
        "id": "d7274617",
        "scrolled": true
      },
      "source": [
        "### Tuning using the method using above (max_depth plot vs acuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "98b7d501",
      "metadata": {
        "id": "98b7d501",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "25b9ac52-9745-4af4-9952-d4488968f698"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "max_depths = np.linspace(1, 15, 15, endpoint=True)\n",
        "\n",
        "train_results = []\n",
        "test_results = []\n",
        "\n",
        "for max_depth in max_depths:\n",
        "    dt = TreeRegressor(max_depth=max_depth)\n",
        "    dt.fit(Xtrain, Ytrain)\n",
        "    Ypred = dt.predict(Xtest)\n",
        "    mseTemp = mean_squared_error(Ytest, Ypred)\n",
        "    test_results.append(mseTemp)\n",
        "    \n",
        "plt.plot(max_depths, test_results)\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Tree depth')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72a95cfe",
      "metadata": {
        "id": "72a95cfe"
      },
      "source": [
        "By tuning the class TreeRegressor through a graph, we get that the max_depth accuracy that minimizes the mse is max_depth = 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fc465de6",
      "metadata": {
        "id": "fc465de6"
      },
      "outputs": [],
      "source": [
        "def make_some_data(n):\n",
        "    x = np.random.uniform(-5, 5, size=n)\n",
        "    Y = (x > 1) + 0.1*np.random.normal(size=n)\n",
        "    X = x.reshape(n, 1) # X needs to be a 2-dimensional matrix\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2014920e",
      "metadata": {
        "id": "2014920e",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "f6cc42b5-8c15-40c9-9d1c-db510a5c0536"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "dataTemp = make_some_data(100)\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.scatter(dataTemp[0], dataTemp[1], cmap='tab10');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07fbae9b",
      "metadata": {
        "id": "07fbae9b"
      },
      "source": [
        "We generate a 100 data point randomly using the data generation function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b04b1ab",
      "metadata": {
        "id": "3b04b1ab"
      },
      "source": [
        "from the plot above, the data looks that it can be best described through a decision tree classifier as the data is very well splitted into two groups in the 2D space, a decision tree classifier can  classify the data points into 2 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1a4594bd",
      "metadata": {
        "id": "1a4594bd"
      },
      "outputs": [],
      "source": [
        "dataTemp = make_some_data(1000)\n",
        "XtrainTemp, XtestTemp, YtrainTemp, YtestTemp = train_test_split(dataTemp[0], dataTemp[1], test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "20feacc8",
      "metadata": {
        "id": "20feacc8"
      },
      "outputs": [],
      "source": [
        "dtrTemp = TreeRegressor(max_depth=5)\n",
        "dtrTemp.fit(XtrainTemp, YtrainTemp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9db0e9d4",
      "metadata": {
        "id": "9db0e9d4"
      },
      "outputs": [],
      "source": [
        "Yguess = dtrTemp.predict(Xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3d4f391f",
      "metadata": {
        "id": "3d4f391f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9a6565-181a-4df2-a007-b3c844a348f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "234.76393219067646"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "mean_squared_error(Ytest,Yguess)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8613d3b8",
      "metadata": {
        "id": "8613d3b8"
      },
      "source": [
        "By training and testing the TreeRegressor class on the data above after splitting it into test and train data, we get a mean square error of 233 on the testing set when the max_depth is set to 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "27c49495",
      "metadata": {
        "id": "27c49495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "5b2e8cf1-3e12-45d2-b276-d552af0ea60f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f8dbbc88110>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"471pt\" height=\"479pt\"\n viewBox=\"0.00 0.00 471.14 479.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 475)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-475 467.1424,-475 467.1424,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"47.4458\" cy=\"-366\" rx=\"47.3916\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"47.4458\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.007426</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"116.4458\" cy=\"-279\" rx=\"50.0912\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"116.4458\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&#45;0.003639</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"189.4458\" cy=\"-192\" rx=\"50.0912\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"189.4458\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&#45;0.004564</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"263.4458\" cy=\"-105\" rx=\"45.4919\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"263.4458\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&#45;0.06577</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"319.4458\" cy=\"-18\" rx=\"50.0912\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"319.4458\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&#45;0.008676</text>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"425.4458\" cy=\"-18\" rx=\"37.8943\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"425.4458\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.3777</text>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#ffff00\" stroke=\"#000000\" d=\"M406.4458,-123C406.4458,-123 338.4458,-123 338.4458,-123 332.4458,-123 326.4458,-117 326.4458,-111 326.4458,-111 326.4458,-99 326.4458,-99 326.4458,-93 332.4458,-87 338.4458,-87 338.4458,-87 406.4458,-87 406.4458,-87 412.4458,-87 418.4458,-93 418.4458,-99 418.4458,-99 418.4458,-111 418.4458,-111 418.4458,-117 412.4458,-123 406.4458,-123\"/>\n<text text-anchor=\"middle\" x=\"372.4458\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F0 &gt; &#45;4.891?</text>\n</g>\n<!-- 6&#45;&gt;4 -->\n<g id=\"edge1\" class=\"edge\">\n<title>6&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M361.4642,-86.9735C353.9528,-74.6435 343.873,-58.0975 335.4689,-44.3021\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"338.4237,-42.4249 330.232,-35.7057 332.4456,-46.0667 338.4237,-42.4249\"/>\n<text text-anchor=\"middle\" x=\"364.4458\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 6&#45;&gt;5 -->\n<g id=\"edge2\" class=\"edge\">\n<title>6&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M383.4274,-86.9735C390.9886,-74.5619 401.1522,-57.8782 409.5894,-44.0284\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"412.6263,-45.7707 414.8399,-35.4097 406.6482,-42.1289 412.6263,-45.7707\"/>\n<text text-anchor=\"middle\" x=\"414.9458\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#ffff00\" stroke=\"#000000\" d=\"M337.4458,-210C337.4458,-210 269.4458,-210 269.4458,-210 263.4458,-210 257.4458,-204 257.4458,-198 257.4458,-198 257.4458,-186 257.4458,-186 257.4458,-180 263.4458,-174 269.4458,-174 269.4458,-174 337.4458,-174 337.4458,-174 343.4458,-174 349.4458,-180 349.4458,-186 349.4458,-186 349.4458,-198 349.4458,-198 349.4458,-204 343.4458,-210 337.4458,-210\"/>\n<text text-anchor=\"middle\" x=\"303.4458\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F0 &gt; &#45;4.909?</text>\n</g>\n<!-- 7&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>7&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M295.1578,-173.9735C289.6336,-161.9585 282.2688,-145.9401 276.0272,-132.3646\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"279.0806,-130.627 271.7232,-123.0034 272.7206,-133.5512 279.0806,-130.627\"/>\n<text text-anchor=\"middle\" x=\"301.4458\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 7&#45;&gt;6 -->\n<g id=\"edge4\" class=\"edge\">\n<title>7&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M317.7426,-173.9735C327.5494,-161.6085 340.7188,-145.0036 351.6786,-131.1847\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"354.6955,-133.0133 358.1673,-123.0034 349.211,-128.6635 354.6955,-133.0133\"/>\n<text text-anchor=\"middle\" x=\"355.9458\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#ffff00\" stroke=\"#000000\" d=\"M264.4458,-297C264.4458,-297 196.4458,-297 196.4458,-297 190.4458,-297 184.4458,-291 184.4458,-285 184.4458,-285 184.4458,-273 184.4458,-273 184.4458,-267 190.4458,-261 196.4458,-261 196.4458,-261 264.4458,-261 264.4458,-261 270.4458,-261 276.4458,-267 276.4458,-273 276.4458,-273 276.4458,-285 276.4458,-285 276.4458,-291 270.4458,-297 264.4458,-297\"/>\n<text text-anchor=\"middle\" x=\"230.4458\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F0 &gt; &#45;4.917?</text>\n</g>\n<!-- 8&#45;&gt;2 -->\n<g id=\"edge5\" class=\"edge\">\n<title>8&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M221.9506,-260.9735C216.2883,-248.9585 208.7394,-232.9401 202.3417,-219.3646\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"205.3592,-217.5571 197.9301,-210.0034 199.0271,-220.5413 205.3592,-217.5571\"/>\n<text text-anchor=\"middle\" x=\"227.4458\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 8&#45;&gt;7 -->\n<g id=\"edge6\" class=\"edge\">\n<title>8&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M245.5714,-260.9735C256.0446,-248.4919 270.1428,-231.6899 281.8022,-217.7944\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"284.5929,-219.9136 288.3395,-210.0034 279.2305,-215.4142 284.5929,-219.9136\"/>\n<text text-anchor=\"middle\" x=\"284.9458\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#ffff00\" stroke=\"#000000\" d=\"M192.4458,-384C192.4458,-384 124.4458,-384 124.4458,-384 118.4458,-384 112.4458,-378 112.4458,-372 112.4458,-372 112.4458,-360 112.4458,-360 112.4458,-354 118.4458,-348 124.4458,-348 124.4458,-348 192.4458,-348 192.4458,-348 198.4458,-348 204.4458,-354 204.4458,-360 204.4458,-360 204.4458,-372 204.4458,-372 204.4458,-378 198.4458,-384 192.4458,-384\"/>\n<text text-anchor=\"middle\" x=\"158.4458\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F0 &gt; &#45;4.946?</text>\n</g>\n<!-- 9&#45;&gt;1 -->\n<g id=\"edge7\" class=\"edge\">\n<title>9&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M149.7434,-347.9735C143.943,-335.9585 136.21,-319.9401 129.6563,-306.3646\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"132.6365,-304.4872 125.1371,-297.0034 126.3327,-307.5305 132.6365,-304.4872\"/>\n<text text-anchor=\"middle\" x=\"155.4458\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 9&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>9&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M173.3642,-347.9735C183.6939,-335.4919 197.599,-318.6899 209.0987,-304.7944\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"211.8671,-306.9388 215.5465,-297.0034 206.4744,-302.4758 211.8671,-306.9388\"/>\n<text text-anchor=\"middle\" x=\"212.9458\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#ffff00\" stroke=\"#000000\" d=\"M107.4458,-471C107.4458,-471 39.4458,-471 39.4458,-471 33.4458,-471 27.4458,-465 27.4458,-459 27.4458,-459 27.4458,-447 27.4458,-447 27.4458,-441 33.4458,-435 39.4458,-435 39.4458,-435 107.4458,-435 107.4458,-435 113.4458,-435 119.4458,-441 119.4458,-447 119.4458,-447 119.4458,-459 119.4458,-459 119.4458,-465 113.4458,-471 107.4458,-471\"/>\n<text text-anchor=\"middle\" x=\"73.4458\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F0 &gt; &#45;4.966?</text>\n</g>\n<!-- 10&#45;&gt;0 -->\n<g id=\"edge9\" class=\"edge\">\n<title>10&#45;&gt;0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M68.0586,-434.9735C64.5027,-423.0751 59.7736,-407.2508 55.7421,-393.7606\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"59.043,-392.5825 52.8261,-384.0034 52.3361,-394.5869 59.043,-392.5825\"/>\n<text text-anchor=\"middle\" x=\"77.4458\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 10&#45;&gt;9 -->\n<g id=\"edge10\" class=\"edge\">\n<title>10&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M91.0578,-434.9735C103.3666,-422.3752 119.9755,-405.3755 133.6243,-391.4055\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"136.3714,-393.6021 140.8563,-384.0034 131.3644,-388.7103 136.3714,-393.6021\"/>\n<text text-anchor=\"middle\" x=\"134.9458\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "dtrTemp.draw_tree()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40dce448",
      "metadata": {
        "id": "40dce448"
      },
      "source": [
        "After drawing the tree, we can see that the result doesn' make sense as the root node started by value = -4.926 and the data was generated on an inteval on [-5,5], so a max_depth 5 as shown in the graph doesn't predict well the values of the data due to the severe deviation of the data values and a small depth such as 5 can't capture all the data points and predict them correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f98e1ae0",
      "metadata": {
        "id": "f98e1ae0"
      },
      "outputs": [],
      "source": [
        "dtr = TreeRegressor(max_depth=5)\n",
        "dtr.fit(Xtrain, Ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2bea195a",
      "metadata": {
        "id": "2bea195a"
      },
      "outputs": [],
      "source": [
        "Yguess = dtr.predict(Xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "44518668",
      "metadata": {
        "id": "44518668",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eaefa4b-af75-4ee6-8a0d-e110cd59d2da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4027607081960747"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "mean_squared_error(Ytest,Yguess)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a25c9026",
      "metadata": {
        "id": "a25c9026"
      },
      "source": [
        "The TreeRegressor class predicted the price of the apartments with a mean squared error of 0.4 on the testing set with <b>max_depth hyperparameter set to 5</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1ad4f265",
      "metadata": {
        "id": "1ad4f265",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "max_depths = np.linspace(1, 12, 12, endpoint=True)\n",
        "\n",
        "train_results = []\n",
        "test_results = []\n",
        "\n",
        "for max_depth in max_depths:\n",
        "    dt = TreeRegressor(max_depth=max_depth)\n",
        "    dt.fit(Xtrain, Ytrain)\n",
        "    YpredTrain = dt.predict(Xtrain)\n",
        "    mseTrain = mean_squared_error(Ytrain, YpredTrain)\n",
        "    Ypredtest = dt.predict(Xtest)\n",
        "    mseTest = mean_squared_error(Ytest, Ypredtest)\n",
        "    train_results.append(mseTrain)\n",
        "    test_results.append(mseTest)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(max_depths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ith5gMJl16s",
        "outputId": "07c6393c-9a44-424a-a188-a2a3ee4409e2"
      },
      "id": "_ith5gMJl16s",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line1, = plt.plot(max_depths,train_results, label=\"Train MSE\")\n",
        "line2, = plt.plot(max_depths,test_results, label=\"Test MSE\")\n",
        "\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Tree depth')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "S0CzFVFcj-bW",
        "outputId": "2886175a-6ed0-4ef6-dba4-800950f69b51"
      },
      "id": "S0CzFVFcj-bW",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1672705",
      "metadata": {
        "id": "b1672705"
      },
      "source": [
        "From the graph above, we can see that when the model is used to predict the training data that it was trained on, it achieved a minimum MSE of 0.38 at tree_depth = 12 (the blue line), while it achieved a testing MSE of 0.395 at tree_depth = 12 when the model is used to predict an unseen testing data (the red line), so we can conclude from the graph above that since the trends of both curves are almost the same when increasing and decreasing the tree_depth while maintaining almost a constant very low difference in the MSE between the training and testing curves, that the model is not overfitting and it predicted the unseen testing data with a proper efficiency compared to its efficiency in predicting the previously seen training data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "a2ef5135",
        "a916571c",
        "f1f30172",
        "e5254264",
        "15729609",
        "77772817",
        "5fe29e13",
        "ca75b7cb",
        "11437f83",
        "a64b2ac8",
        "a6f1f487",
        "5b9f0c2a",
        "e4f2ddc7",
        "8b2271ea",
        "60f77544",
        "32721214",
        "4e773839",
        "e31c23fa",
        "c11cb375",
        "86df3959",
        "a1a1943e",
        "e5556167",
        "737aa16b",
        "d7274617",
        "b20dff78",
        "90a0fbd1",
        "6024f118",
        "f817912c"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}